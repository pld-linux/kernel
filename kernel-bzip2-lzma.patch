diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/arch/x86/boot/compressed/head_32.S linux-2.6.26.3udpcast/arch/x86/boot/compressed/head_32.S
--- linux-2.6.26.3/arch/x86/boot/compressed/head_32.S	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/arch/x86/boot/compressed/head_32.S	2008-09-06 12:23:22.000000000 +0200
@@ -75,7 +75,11 @@ startup_32:
 
 	/* Replace the compressed data size with the uncompressed size */
 	subl input_len(%ebp), %ebx
+#ifdef CONFIG_KERNEL_LZMA
+	movl output_len_lzma(%ebp), %eax
+#else
 	movl output_len(%ebp), %eax
+#endif
 	addl %eax, %ebx
 	/* Add 8 bytes for every 32K input block */
 	shrl $12, %eax
@@ -135,7 +139,11 @@ relocated:
 /*
  * Do the decompression, and jump to the new kernel..
  */
+#ifdef CONFIG_KERNEL_LZMA
+	movl output_len_lzma(%ebx), %eax
+#else
 	movl output_len(%ebx), %eax
+#endif
 	pushl %eax
 	pushl %ebp	# output address
 	movl input_len(%ebx), %eax
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/arch/x86/boot/compressed/head_64.S linux-2.6.26.3udpcast/arch/x86/boot/compressed/head_64.S
--- linux-2.6.26.3/arch/x86/boot/compressed/head_64.S	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/arch/x86/boot/compressed/head_64.S	2008-09-06 21:27:59.000000000 +0200
@@ -89,7 +89,11 @@ startup_32:
 
 	/* Replace the compressed data size with the uncompressed size */
 	subl	input_len(%ebp), %ebx
+#ifdef CONFIG_KERNEL_LZMA
+	movl	output_len_lzma(%ebp), %eax
+#else
 	movl	output_len(%ebp), %eax
+#endif
 	addl	%eax, %ebx
 	/* Add 8 bytes for every 32K input block */
 	shrl	$12, %eax
@@ -232,7 +236,11 @@ ENTRY(startup_64)
 	/* Replace the compressed data size with the uncompressed size */
 	movl	input_len(%rip), %eax
 	subq	%rax, %rbx
+#ifdef CONFIG_KERNEL_LZMA
+	movl	output_len_lzma(%rip), %eax
+#else
 	movl	output_len(%rip), %eax
+#endif
 	addq	%rax, %rbx
 	/* Add 8 bytes for every 32K input block */
 	shrq	$12, %rax
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/arch/x86/boot/compressed/Makefile linux-2.6.26.3udpcast/arch/x86/boot/compressed/Makefile
--- linux-2.6.26.3/arch/x86/boot/compressed/Makefile	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/arch/x86/boot/compressed/Makefile	2008-09-04 20:04:13.000000000 +0200
@@ -4,7 +4,7 @@
 # create a compressed vmlinux image from the original vmlinux
 #
 
-targets := vmlinux vmlinux.bin vmlinux.bin.gz head_$(BITS).o misc.o piggy.o
+targets := vmlinux vmlinux.bin vmlinux.bin.gz vmlinux.bin.bz2 vmlinux.bin.lzma head_$(BITS).o misc.o piggy.o
 
 KBUILD_CFLAGS := -m$(BITS) -D__KERNEL__ $(LINUX_INCLUDE) -O2
 KBUILD_CFLAGS += -fno-strict-aliasing -fPIC
@@ -46,19 +46,34 @@ $(obj)/vmlinux.bin.all: $(vmlinux.bin.al
 ifdef CONFIG_RELOCATABLE
 $(obj)/vmlinux.bin.gz: $(obj)/vmlinux.bin.all FORCE
 	$(call if_changed,gzip)
+$(obj)/vmlinux.bin.bz2: $(obj)/vmlinux.bin.all FORCE
+	$(call if_changed,bzip2)
+$(obj)/vmlinux.bin.lzma: $(obj)/vmlinux.bin.all FORCE
+	$(call if_changed,lzma)
 else
 $(obj)/vmlinux.bin.gz: $(obj)/vmlinux.bin FORCE
 	$(call if_changed,gzip)
+$(obj)/vmlinux.bin.bz2: $(obj)/vmlinux.bin FORCE
+	$(call if_changed,bzip2)
+$(obj)/vmlinux.bin.lzma: $(obj)/vmlinux.bin FORCE
+	$(call if_changed,lzma)
 endif
 LDFLAGS_piggy.o := -r --format binary --oformat elf32-i386 -T
 
 else
 $(obj)/vmlinux.bin.gz: $(obj)/vmlinux.bin FORCE
 	$(call if_changed,gzip)
+$(obj)/vmlinux.bin.bz2: $(obj)/vmlinux.bin FORCE
+	$(call if_changed,bzip2)
+$(obj)/vmlinux.bin.lzma: $(obj)/vmlinux.bin FORCE
+	$(call if_changed,lzma)
 
 LDFLAGS_piggy.o := -r --format binary --oformat elf64-x86-64 -T
 endif
 
+suffix_$(CONFIG_KERNEL_GZIP)  = gz
+suffix_$(CONFIG_KERNEL_BZIP2) = bz2
+suffix_$(CONFIG_KERNEL_LZMA)  = lzma
 
-$(obj)/piggy.o: $(obj)/vmlinux.scr $(obj)/vmlinux.bin.gz FORCE
+$(obj)/piggy.o: $(obj)/vmlinux.scr $(obj)/vmlinux.bin.$(suffix_y) FORCE
 	$(call if_changed,ld)
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/arch/x86/boot/compressed/misc.c linux-2.6.26.3udpcast/arch/x86/boot/compressed/misc.c
--- linux-2.6.26.3/arch/x86/boot/compressed/misc.c	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/arch/x86/boot/compressed/misc.c	2008-09-06 21:34:29.000000000 +0200
@@ -136,11 +136,15 @@ typedef unsigned long	ulg;
 #define WSIZE		0x80000000
 
 /* Input buffer: */
+
+#ifdef CONFIG_KERNEL_GZIP
 static unsigned char	*inbuf;
+#endif
 
 /* Sliding window buffer (and final output buffer): */
 static unsigned char	*window;
 
+#ifdef CONFIG_KERNEL_GZIP
 /* Valid bytes in inbuf: */
 static unsigned		insize;
 
@@ -180,9 +184,14 @@ static unsigned		outcnt;
 
 static int  fill_inbuf(void);
 static void flush_window(void);
+#endif
+
 static void error(char *m);
+
+#ifdef CONFIG_KERNEL_GZIP
 static void gzip_mark(void **);
 static void gzip_release(void **);
+#endif
 
 /*
  * This is set up by the setup-routine at boot-time
@@ -203,7 +212,9 @@ static long bytes_out;
 static void *malloc(int size);
 static void free(void *where);
 
+#if (defined CONFIG_KERNEL_GZIP || defined CONFIG_KERNEL_BZIP2)
 static void *memset(void *s, int c, unsigned n);
+#endif
 static void *memcpy(void *dest, const void *src, unsigned n);
 
 static void putstr(const char *);
@@ -225,7 +236,30 @@ static int lines, cols;
 void *xquad_portio;
 #endif
 
+#if (defined CONFIG_KERNEL_BZIP2 || defined CONFIG_KERNEL_LZMA)
+
+#define large_malloc malloc
+#define large_free free
+
+#ifdef current
+#undef current
+#endif
+
+#define INCLUDED
+#endif
+
+#ifdef CONFIG_KERNEL_GZIP
 #include "../../../../lib/inflate.c"
+#endif
+
+#ifdef CONFIG_KERNEL_BZIP2
+#include "../../../../lib/decompress_bunzip2.c"
+#endif
+
+#ifdef CONFIG_KERNEL_LZMA
+#define IN_MEMORY
+#include "../../../../lib/decompress_unlzma.c"
+#endif
 
 static void *malloc(int size)
 {
@@ -251,6 +285,7 @@ static void free(void *where)
 {	/* Don't care */
 }
 
+#ifdef CONFIG_KERNEL_GZIP
 static void gzip_mark(void **ptr)
 {
 	*ptr = (void *) free_mem_ptr;
@@ -260,6 +295,7 @@ static void gzip_release(void **ptr)
 {
 	free_mem_ptr = (memptr) *ptr;
 }
+#endif
 
 static void scroll(void)
 {
@@ -312,6 +348,7 @@ static void putstr(const char *s)
 	outb(0xff & (pos >> 1), vidport+1);
 }
 
+#if (defined CONFIG_KERNEL_GZIP || defined CONFIG_KERNEL_BZIP2)
 static void *memset(void *s, int c, unsigned n)
 {
 	int i;
@@ -320,6 +357,7 @@ static void *memset(void *s, int c, unsi
 	for (i = 0; i < n; i++) ss[i] = c;
 	return s;
 }
+#endif
 
 static void *memcpy(void *dest, const void *src, unsigned n)
 {
@@ -331,6 +369,27 @@ static void *memcpy(void *dest, const vo
 	return dest;
 }
 
+#ifndef CONFIG_KERNEL_GZIP
+/* ===========================================================================
+ * Write the output window window[0..outcnt-1] and update bytes_out.
+ * (Used for the decompressed data only.)
+ */
+static int compr_flush(void *datav, unsigned int len)
+{
+    char *data = (char *) datav;
+    unsigned n;
+    uch *out;
+
+    out = window;
+    for (n = 0; n < len; n++)
+	    *out++ = *data++;
+
+    bytes_out += (ulg)len;
+    window += (ulg)len;
+    return len;
+}
+
+#else
 /* ===========================================================================
  * Fill the input buffer. This is called only when the buffer is empty
  * and at least one byte is really needed.
@@ -363,6 +422,7 @@ static void flush_window(void)
 	bytes_out += (unsigned long)outcnt;
 	outcnt = 0;
 }
+#endif
 
 static void error(char *x)
 {
@@ -444,9 +504,11 @@ asmlinkage void decompress_kernel(void *
 	window = output;		/* Output buffer (Normally at 1M) */
 	free_mem_ptr     = heap;	/* Heap */
 	free_mem_end_ptr = heap + BOOT_HEAP_SIZE;
+#ifdef CONFIG_KERNEL_GZIP
 	inbuf  = input_data;		/* Input buffer */
 	insize = input_len;
 	inptr  = 0;
+#endif
 
 #ifdef CONFIG_X86_64
 	if ((unsigned long)output & (__KERNEL_ALIGN - 1))
@@ -464,9 +526,20 @@ asmlinkage void decompress_kernel(void *
 #endif
 #endif
 
+#ifdef CONFIG_KERNEL_BZIP2
+	putstr("\nBunzipping Linux... ");
+	bunzip2(input_data, input_len-4, NULL, compr_flush, NULL);
+#endif
+#ifdef CONFIG_KERNEL_LZMA
+	putstr("\nUnlzmaing Linux... ");
+	unlzma(input_data, input_len, NULL, output, NULL);
+#endif
+
+#ifdef CONFIG_KERNEL_GZIP
 	makecrc();
 	putstr("\nDecompressing Linux... ");
 	gunzip();
+#endif
 	parse_elf(output);
 	putstr("done.\nBooting the kernel.\n");
 	return;
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/arch/x86/boot/compressed/vmlinux.scr linux-2.6.26.3udpcast/arch/x86/boot/compressed/vmlinux.scr
--- linux-2.6.26.3/arch/x86/boot/compressed/vmlinux.scr	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/arch/x86/boot/compressed/vmlinux.scr	2008-09-06 21:31:55.000000000 +0200
@@ -3,6 +3,7 @@ SECTIONS
   .rodata.compressed : {
 	input_len = .;
 	LONG(input_data_end - input_data) input_data = .;
+	output_len_lzma = . + 5;
 	*(.data)
 	output_len = . - 4;
 	input_data_end = .;
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/Documentation/dontdiff linux-2.6.26.3udpcast/Documentation/dontdiff
--- linux-2.6.26.3/Documentation/dontdiff	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/Documentation/dontdiff	2008-09-06 22:04:53.000000000 +0200
@@ -183,10 +183,18 @@ vmlinux
 vmlinux-*
 vmlinux.aout
 vmlinux*.lds*
-vmlinux*.scr
 vsyscall.lds
 wanxlfw.inc
 uImage
 unifdef
 zImage*
 zconf.hash.c
+bounds.h
+cpustr.h
+vdso-syms.lds
+vdso.so.dbg
+mkcpustr
+vmlinux.bin.all
+vmlinux.bin.lzma
+vmlinux.bin.bz2
+vmlinux.bin.gz
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/drivers/block/Kconfig linux-2.6.26.3udpcast/drivers/block/Kconfig
--- linux-2.6.26.3/drivers/block/Kconfig	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/drivers/block/Kconfig	2008-09-03 19:47:02.000000000 +0200
@@ -357,6 +357,30 @@ config BLK_DEV_XIP
 	  will prevent RAM block device backing store memory from being
 	  allocated from highmem (only a problem for highmem systems).
 
+config RD_BZIP2
+	bool "Initial ramdisk compressed using bzip2"
+	default n
+	depends on BLK_DEV_INITRD=y
+	help
+	  Support loading of a bzip2 encoded initial ramdisk or cpio buffer
+	  If unsure, say N.
+
+config RD_LZMA
+	bool "Initial ramdisk compressed using lzma"
+	default n
+	depends on BLK_DEV_INITRD=y
+	help
+	  Support loading of a lzma encoded initial ramdisk or cpio buffer
+	  If unsure, say N.
+
+config RD_GZIP
+	bool "Initial ramdisk compressed using gzip"
+	default y
+	depends on BLK_DEV_INITRD=y
+	help
+	  Support loading of a gzip encoded initial ramdisk or cpio buffer.
+	  If unsure, say Y.
+
 config CDROM_PKTCDVD
 	tristate "Packet writing on CD/DVD media"
 	depends on !UML
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/include/asm-x86/boot.h linux-2.6.26.3udpcast/include/asm-x86/boot.h
--- linux-2.6.26.3/include/asm-x86/boot.h	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/include/asm-x86/boot.h	2008-09-06 21:33:56.000000000 +0200
@@ -17,12 +17,23 @@
 				+ (CONFIG_PHYSICAL_ALIGN - 1)) \
 				& ~(CONFIG_PHYSICAL_ALIGN - 1))
 
+#if (defined CONFIG_KERNEL_BZIP2 || defined CONFIG_KERNEL_LZMA)
+#define BOOT_HEAP_SIZE             0x400000
+#else
+
 #ifdef CONFIG_X86_64
 #define BOOT_HEAP_SIZE	0x7000
-#define BOOT_STACK_SIZE	0x4000
 #else
 #define BOOT_HEAP_SIZE	0x4000
+#endif
+
+#endif
+
+#ifdef CONFIG_X86_64
+#define BOOT_STACK_SIZE	0x4000
+#else
 #define BOOT_STACK_SIZE	0x1000
 #endif
 
+
 #endif /* _ASM_BOOT_H */
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/include/linux/decompress_bunzip2.h linux-2.6.26.3udpcast/include/linux/decompress_bunzip2.h
--- linux-2.6.26.3/include/linux/decompress_bunzip2.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.26.3udpcast/include/linux/decompress_bunzip2.h	2008-09-05 23:51:20.000000000 +0200
@@ -0,0 +1,20 @@
+#ifndef DECOMPRESS_BUNZIP2_H
+#define DECOMPRESS_BUNZIP2_H
+
+/* Other housekeeping constants */
+#define BZIP2_IOBUF_SIZE		4096
+
+#ifndef STATIC
+#define STATIC extern
+#endif
+
+#ifndef INIT
+#define INIT /* */
+#endif
+
+STATIC int INIT bunzip2(char *inbuf, int len,
+			int(*fill)(void*, unsigned int),
+			int(*flush)(void*, unsigned int),
+			int *pos);
+
+#endif
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/include/linux/decompress_generic.h linux-2.6.26.3udpcast/include/linux/decompress_generic.h
--- linux-2.6.26.3/include/linux/decompress_generic.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.26.3udpcast/include/linux/decompress_generic.h	2008-09-05 17:47:11.000000000 +0200
@@ -0,0 +1,28 @@
+#ifndef DECOMPRESS_GENERIC_H
+#define DECOMPRESS_GENERIC_H
+
+/* Minimal chunksize to be read.
+ *Bzip2 prefers at least 4096
+ *Lzma prefers 0x10000 */
+#define COMPR_IOBUF_SIZE	4096
+
+typedef int (*uncompress_fn) (char *inbuf, int len,
+			      int(*fill)(char*, unsigned int),
+			      int(*writebb)(char*, unsigned int),
+			      int *posp);
+
+/* inbuf   - input buffer
+ *len     - len of pre-read data in inbuf
+ *fill    - function to fill inbuf if empty
+ *writebb - function to write out outbug
+ *posp    - if non-null, input position (number of bytes read) will be
+ *	  returned here
+ *
+ *If len != 0, the inbuf is initialized (with as much data), and fill
+ *should not be called
+ *If len = 0, the inbuf is allocated, but empty. Its size is IOBUF_SIZE
+ *fill should be called (repeatedly...) to read data, at most IOBUF_SIZE
+ */
+
+
+#endif
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/include/linux/decompress_unlzma.h linux-2.6.26.3udpcast/include/linux/decompress_unlzma.h
--- linux-2.6.26.3/include/linux/decompress_unlzma.h	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.26.3udpcast/include/linux/decompress_unlzma.h	2008-09-06 10:03:46.000000000 +0200
@@ -0,0 +1,24 @@
+#ifndef DECOMPRESS_UNLZMA_H
+#define DECOMPRESS_UNLZMA_H
+
+#define LZMA_IOBUF_SIZE	0x10000
+
+#ifndef STATIC
+#define STATIC extern
+#endif
+
+#ifndef INIT
+#define INIT /* */
+#endif
+
+STATIC int unlzma(char *, int,
+		  int(*fill)(void*, unsigned int),
+#ifdef IN_MEMORY
+		  unsigned char *output,
+#else
+		  int(*flush)(void*, unsigned int),
+#endif
+		  int *
+	);
+
+#endif
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/init/do_mounts_rd.c linux-2.6.26.3udpcast/init/do_mounts_rd.c
--- linux-2.6.26.3/init/do_mounts_rd.c	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/init/do_mounts_rd.c	2008-09-05 17:35:30.000000000 +0200
@@ -8,6 +8,7 @@
 #include <linux/squashfs_fs.h>
 #include <linux/initrd.h>
 #include <linux/string.h>
+#include <linux/decompress_unlzma.h>
 
 #include "do_mounts.h"
 
@@ -30,7 +30,15 @@ static int __init ramdisk_start_setup(ch
 }
 __setup("ramdisk_start=", ramdisk_start_setup);
 
+#ifdef CONFIG_RD_GZIP
 static int __init crd_load(int in_fd, int out_fd);
+#endif
+#ifdef CONFIG_RD_BZIP2
+static int __init crd_load_bzip2(int in_fd, int out_fd);
+#endif
+#ifdef CONFIG_RD_LZMA
+static int __init crd_load_lzma(int in_fd, int out_fd);
+#endif
 
 /*
  * This routine tries to find a RAM disk image to load, and returns the
@@ -46,7 +54,7 @@ static int __init crd_load(int in_fd, in
  * 	gzip
  */
 static int __init 
-identify_ramdisk_image(int fd, int start_block)
+identify_ramdisk_image(int fd, int start_block, int *ztype)
 {
 	const int size = 512;
 	struct minix_super_block *minixsb;
@@ -72,6 +80,7 @@ identify_ramdisk_image(int fd, int start
 	sys_lseek(fd, start_block * BLOCK_SIZE, 0);
 	sys_read(fd, buf, size);
 
+#ifdef CONFIG_RD_GZIP
 	/*
 	 * If it matches the gzip magic numbers, return -1
 	 */
@@ -79,9 +88,39 @@ identify_ramdisk_image(int fd, int start
 		printk(KERN_NOTICE
 		       "RAMDISK: Compressed image found at block %d\n",
 		       start_block);
+		*ztype = 0;
+		nblocks = 0;
+		goto done;
+	}
+#endif
+
+#ifdef CONFIG_RD_BZIP2
+	/*
+	 * If it matches the bzip magic numbers, return -1
+	 */
+	if (buf[0] == 0x42 && (buf[1] == 0x5a)) {
+		printk(KERN_NOTICE
+		       "RAMDISK: Bzipped image found at block %d\n",
+		       start_block);
+		*ztype = 1;
+		nblocks = 0;
+		goto done;
+	}
+#endif
+
+#ifdef CONFIG_RD_LZMA
+	/*
+	 * If it matches the bzip magic numbers, return -1
+	 */
+	if (buf[0] == 0x5d && (buf[1] == 0x00)) {
+		printk(KERN_NOTICE
+		       "RAMDISK: Lzma image found at block %d\n",
+		       start_block);
+		*ztype = 2;
 		nblocks = 0;
 		goto done;
 	}
+#endif
 
 	/* romfs is at block zero too */
 	if (romfsb->word0 == ROMSB_WORD0 &&
@@ -145,6 +184,7 @@ int __init rd_load_image(char *from)
 	int nblocks, i, disk;
 	char *buf = NULL;
 	unsigned short rotate = 0;
+	int ztype = -1;
 #if !defined(CONFIG_S390) && !defined(CONFIG_PPC_ISERIES)
 	char rotator[4] = { '|' , '/' , '-' , '\\' };
 #endif
@@ -157,14 +197,38 @@ int __init rd_load_image(char *from)
 	if (in_fd < 0)
 		goto noclose_input;
 
-	nblocks = identify_ramdisk_image(in_fd, rd_image_start);
+	nblocks = identify_ramdisk_image(in_fd, rd_image_start, &ztype);
 	if (nblocks < 0)
 		goto done;
 
 	if (nblocks == 0) {
 #ifdef BUILD_CRAMDISK
-		if (crd_load(in_fd, out_fd) == 0)
-			goto successful_load;
+		switch (ztype) {
+
+#ifdef CONFIG_RD_GZIP
+		case 0:
+			if (crd_load(in_fd, out_fd) == 0)
+				goto successful_load;
+			break;
+#endif
+
+#ifdef CONFIG_RD_BZIP2
+		case 1:
+			if (crd_load_bzip2(in_fd, out_fd) == 0)
+				goto successful_load;
+			break;
+#endif
+
+#ifdef CONFIG_RD_LZMA
+		case 2:
+			if (crd_load_lzma(in_fd, out_fd) == 0)
+				goto successful_load;
+			break;
+#endif
+
+		default:
+			break;
+		}
 #else
 		printk(KERN_NOTICE
 		       "RAMDISK: Kernel does not support compressed "
@@ -269,6 +333,7 @@ int __init rd_load_disk(int n)
 
 #ifdef BUILD_CRAMDISK
 
+#ifdef CONFIG_RD_GZIP
 /*
  * gzip declarations
  */
@@ -296,8 +361,11 @@ static unsigned outcnt;  /* bytes in out
 static int exit_code;
 static int unzip_error;
 static long bytes_out;
+#endif
+
 static int crd_infd, crd_outfd;
 
+#ifdef CONFIG_RD_GZIP
 #define get_byte()  (inptr < insize ? inbuf[inptr++] : fill_inbuf())
 		
 /* Diagnostic functions (stubbed out) */
@@ -321,6 +389,16 @@ static void __init gzip_release(void **)
 
 #include "../lib/inflate.c"
 
+#ifdef CONFIG_RD_BZIP2
+#include <linux/decompress_bunzip2.h>
+#undef STATIC
+#endif
+
+#ifdef CONFIG_RD_LZMA
+#include <linux/decompress_unlzma.h>
+#undef STATIC
+#endif
+
 static void __init *malloc(size_t size)
 {
 	return kmalloc(size, GFP_KERNEL);
@@ -359,7 +437,21 @@ static int __init fill_inbuf(void)
 
 	return inbuf[0];
 }
+#endif
 
+#if (defined CONFIG_RD_BZIP2 || defined CONFIG_RD_LZMA)
+static int __init compr_fill(void *buf, unsigned int len)
+{
+	int r = sys_read(crd_infd, buf, len);
+	if (r < 0)
+		printk(KERN_ERR "RAMDISK: error while reading compressed data");
+	else if (r == 0)
+		printk(KERN_ERR "RAMDISK: EOF while reading compressed data");
+	return r;
+}
+#endif
+
+#ifdef CONFIG_RD_GZIP
 /* ===========================================================================
  * Write the output window window[0..outcnt-1] and update crc and bytes_out.
  * (Used for the decompressed data only.)
@@ -385,7 +477,21 @@ static void __init flush_window(void)
     bytes_out += (ulg)outcnt;
     outcnt = 0;
 }
+#endif
 
+#if (defined CONFIG_RD_BZIP2 || defined CONFIG_RD_LZMA)
+static int __init compr_flush(void *window, unsigned int outcnt)
+{
+	int written = sys_write(crd_outfd, window, outcnt);
+	if (written != outcnt) {
+		printk(KERN_ERR "RAMDISK: incomplete write (%d != %d)\n",
+		       written, outcnt);
+	}
+	return outcnt;
+}
+#endif
+
+#ifdef CONFIG_RD_GZIP
 static void __init error(char *x)
 {
 	printk(KERN_ERR "%s\n", x);
@@ -425,5 +531,43 @@ static int __init crd_load(int in_fd, in
 	kfree(window);
 	return result;
 }
+#endif
+
+#if (defined CONFIG_RD_BZIP2 || defined CONFIG_RD_LZMA)
+static int __init crd_load_compr(int in_fd, int out_fd, int size,
+				 int (*deco)(char *, int,
+					     int(*fill)(void*, unsigned int),
+					     int(*flush)(void*, unsigned int),
+					     int *))
+{
+	int result;
+	char *inbuf = kmalloc(size, GFP_KERNEL);
+	crd_infd = in_fd;
+	crd_outfd = out_fd;
+	if (inbuf == 0) {
+		printk(KERN_ERR
+			"RAMDISK: Couldn't allocate decompression buffer\n");
+		return -1;
+	}
+	result = deco(inbuf, 0, compr_fill, compr_flush, NULL);
+	kfree(inbuf);
+	return result;
+}
+#endif
+
+#ifdef CONFIG_RD_BZIP2
+static int __init crd_load_bzip2(int in_fd, int out_fd)
+{
+	return crd_load_compr(in_fd, out_fd, BZIP2_IOBUF_SIZE, bunzip2);
+}
+#endif
+
+#ifdef CONFIG_RD_LZMA
+static int __init crd_load_lzma(int in_fd, int out_fd)
+{
+	return crd_load_compr(in_fd, out_fd, LZMA_IOBUF_SIZE, unlzma);
+}
+
+#endif
 
 #endif  /* BUILD_CRAMDISK */
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/init/initramfs.c linux-2.6.26.3udpcast/init/initramfs.c
--- linux-2.6.26.3/init/initramfs.c	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/init/initramfs.c	2008-09-06 00:01:10.000000000 +0200
@@ -7,6 +7,15 @@
 #include <linux/string.h>
 #include <linux/syscalls.h>
 
+/* We need to enable RD_GZIP unconditionnally, as the built-in
+ * initramfs is gzip-compressed, alas!
+ * We can only wonder why, though, as the whole kernel (which contains
+ * built-in initramfs) is gzip (or bzip) compressed anyways afterwards...
+ */
+#ifndef CONFIG_RD_GZIP
+#define CONFIG_RD_GZIP
+#endif
+
 static __initdata char *message;
 static void __init error(char *x)
 {
@@ -347,11 +356,14 @@ static int __init write_buffer(char *buf
 	return len - count;
 }
 
-static void __init flush_buffer(char *buf, unsigned len)
+
+static int __init flush_buffer(void *bufv, unsigned len)
 {
+	char *buf = (char *) bufv;
 	int written;
+	int origLen = len;
 	if (message)
-		return;
+		return -1;
 	while ((written = write_buffer(buf, len)) < len && !message) {
 		char c = buf[written];
 		if (c == '0') {
@@ -365,8 +377,12 @@ static void __init flush_buffer(char *bu
 		} else
 			error("junk in compressed archive");
 	}
+	return origLen;
 }
 
+static unsigned inptr;   /* index of next byte to be processed in inbuf */
+
+#ifdef CONFIG_RD_GZIP
 /*
  * gzip declarations
  */
@@ -388,7 +404,6 @@ static uch *inbuf;
 static uch *window;
 
 static unsigned insize;  /* valid bytes in inbuf */
-static unsigned inptr;   /* index of next byte to be processed in inbuf */
 static unsigned outcnt;  /* bytes in output buffer */
 static long bytes_out;
 
@@ -412,6 +427,16 @@ static void __init gzip_release(void **)
 
 #include "../lib/inflate.c"
 
+#ifdef CONFIG_RD_BZIP2
+#include <linux/decompress_bunzip2.h>
+
+#endif
+
+#ifdef CONFIG_RD_LZMA
+#include <linux/decompress_unlzma.h>
+
+#endif
+
 static void __init gzip_mark(void **ptr)
 {
 }
@@ -440,6 +465,7 @@ static void __init flush_window(void)
 	bytes_out += (ulg)outcnt;
 	outcnt = 0;
 }
+#endif
 
 static char * __init unpack_to_rootfs(char *buf, unsigned len, int check_only)
 {
@@ -448,9 +474,11 @@ static char * __init unpack_to_rootfs(ch
 	header_buf = kmalloc(110, GFP_KERNEL);
 	symlink_buf = kmalloc(PATH_MAX + N_ALIGN(PATH_MAX) + 1, GFP_KERNEL);
 	name_buf = kmalloc(N_ALIGN(PATH_MAX), GFP_KERNEL);
+#ifdef CONFIG_RD_GZIP
 	window = kmalloc(WSIZE, GFP_KERNEL);
 	if (!window || !header_buf || !symlink_buf || !name_buf)
 		panic("can't allocate buffers");
+#endif
 	state = Start;
 	this_header = 0;
 	message = NULL;
@@ -470,6 +498,7 @@ static char * __init unpack_to_rootfs(ch
 			continue;
 		}
 		this_header = 0;
+#ifdef CONFIG_RD_GZIP
 		insize = len;
 		inbuf = buf;
 		inptr = 0;
@@ -477,14 +506,38 @@ static char * __init unpack_to_rootfs(ch
 		bytes_out = 0;
 		crc = (ulg)0xffffffffL; /* shift register contents */
 		makecrc();
-		gunzip();
+		if (!gunzip() && message == NULL)
+			goto ok;
+#endif
+
+#ifdef CONFIG_RD_BZIP2
+		message = NULL; /* Zero out message, or else cpio will
+				   think an error has already occured */
+		if (!bunzip2(buf, len, NULL, flush_buffer, &inptr) < 0 &&
+		   message == NULL) {
+			goto ok;
+		}
+#endif
+
+#ifdef CONFIG_RD_LZMA
+		message = NULL; /* Zero out message, or else cpio will
+				   think an error has already occured */
+		if (!unlzma(buf, len, NULL, flush_buffer, &inptr) < 0 &&
+		   message == NULL) {
+			goto ok;
+		}
+#endif
+ok:
+
 		if (state != Reset)
-			error("junk in gzipped archive");
+			error("junk in compressed archive");
 		this_header = saved_offset + inptr;
 		buf += inptr;
 		len -= inptr;
 	}
+#ifdef CONFIG_RD_GZIP
 	kfree(window);
+#endif
 	kfree(name_buf);
 	kfree(symlink_buf);
 	kfree(header_buf);
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/init/Kconfig linux-2.6.26.3udpcast/init/Kconfig
--- linux-2.6.26.3/init/Kconfig	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/init/Kconfig	2008-09-05 07:35:43.000000000 +0200
@@ -101,6 +101,56 @@ config LOCALVERSION_AUTO
 
 	  which is done within the script "scripts/setlocalversion".)
 
+choice
+        prompt "Kernel compression mode"
+        default KERNEL_GZIP
+        help
+	  The linux kernel is a kind of self-extracting executable.
+	  Several compression algorithms are available, which differ
+	  in efficiency, compression and decompression speed.
+	  Compression speed is only relevant when building a kernel.
+	  Decompression speed is relevant at each boot.
+
+	  If you have any problems with bzip2 or lzma compressed
+	  kernels, mail me (Alain Knaff) <alain@knaff.lu>. (An older
+	  version of this functionality (bzip2 only), for 2.4, was
+	  supplied by Christian Ludwig)
+
+	  High compression options are mostly useful for users, who
+	  are low on disk space (embedded systems), but for whom ram
+	  size matters less.
+
+	  If in doubt, select 'gzip'
+
+config KERNEL_GZIP
+       bool "Gzip"
+       help
+         The old and tried gzip compression. Its compression ratio is
+	 the poorest among the 3 choices; however its speed (both
+	 compression and decompression) is the fastest.
+
+config KERNEL_BZIP2
+	bool "Bzip2"
+	help
+	  Its compression ratio and speed is intermediate.
+	  Decompression speed is slowest among the 3.
+	  The kernel size is about 10 per cent smaller with bzip2,
+	  in comparison to gzip.
+	  Bzip2 uses a large amount of memory. For modern kernels
+	  you will need at least 8MB RAM or more for booting.
+
+config KERNEL_LZMA
+       bool "LZMA"
+       help
+         The most recent compression algorithm.
+	 Its ratio is best, decompression speed is between the other
+	 2. Compression is slowest.
+	 The kernel size is about 33 per cent smaller with lzma,
+	 in comparison to gzip.
+
+endchoice
+
+
 config SWAP
 	bool "Support for paging of anonymous memory (swap)"
 	depends on MMU && BLOCK
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/lib/decompress_bunzip2.c linux-2.6.26.3udpcast/lib/decompress_bunzip2.c
--- linux-2.6.26.3/lib/decompress_bunzip2.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.26.3udpcast/lib/decompress_bunzip2.c	2008-09-06 11:56:08.000000000 +0200
@@ -0,0 +1,754 @@
+/* vi: set sw = 4 ts = 4: */
+/*	Small bzip2 deflate implementation, by Rob Landley (rob@landley.net).
+
+	Based on bzip2 decompression code by Julian R Seward (jseward@acm.org),
+	which also acknowledges contributions by Mike Burrows, David Wheeler,
+	Peter Fenwick, Alistair Moffat, Radford Neal, Ian H. Witten,
+	Robert Sedgewick, and Jon L. Bentley.
+
+	This code is licensed under the LGPLv2:
+		LGPL (http://www.gnu.org/copyleft/lgpl.html
+*/
+
+/*
+	Size and speed optimizations by Manuel Novoa III  (mjn3@codepoet.org).
+
+	More efficient reading of Huffman codes, a streamlined read_bunzip()
+	function, and various other tweaks.  In (limited) tests, approximately
+	20% faster than bzcat on x86 and about 10% faster on arm.
+
+	Note that about 2/3 of the time is spent in read_unzip() reversing
+	the Burrows-Wheeler transformation.  Much of that time is delay
+	resulting from cache misses.
+
+	I would ask that anyone benefiting from this work, especially those
+	using it in commercial products, consider making a donation to my local
+	non-profit hospice organization in the name of the woman I loved, who
+	passed away Feb. 12, 2003.
+
+		In memory of Toni W. Hagan
+
+		Hospice of Acadiana, Inc.
+		2600 Johnston St., Suite 200
+		Lafayette, LA 70503-3240
+
+		Phone (337) 232-1234 or 1-800-738-2226
+		Fax   (337) 232-1297
+
+		http://www.hospiceacadiana.com/
+
+	Manuel
+ */
+
+/*
+	Made it fit for running in Linux Kernel by Alain Knaff (alain@knaff.lu)
+*/
+
+
+#ifndef STATIC
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/string.h>
+
+#ifdef TEST
+#include "test.h"
+#else
+#include <linux/vmalloc.h>
+#endif
+
+static void __init *large_malloc(size_t size)
+{
+	return vmalloc(size);
+}
+
+static void __init large_free(void *where)
+{
+	vfree(where);
+}
+
+#ifndef TEST
+static void __init *malloc(size_t size)
+{
+	return kmalloc(size, GFP_KERNEL);
+}
+
+static void __init free(void *where)
+{
+	kfree(where);
+}
+
+static void __init error(char *x)
+{
+	printk(KERN_ERR "%s\n", x);
+}
+#endif
+
+#define STATIC /**/
+
+#endif
+
+#ifndef INIT
+#define INIT
+#endif
+
+#include <linux/decompress_bunzip2.h>
+
+
+/* Constants for Huffman coding */
+#define MAX_GROUPS		6
+#define GROUP_SIZE   		50	/* 64 would have been more efficient */
+#define MAX_HUFCODE_BITS 	20	/* Longest Huffman code allowed */
+#define MAX_SYMBOLS 		258	/* 256 literals + RUNA + RUNB */
+#define SYMBOL_RUNA		0
+#define SYMBOL_RUNB		1
+
+/* Status return values */
+#define RETVAL_OK			0
+#define RETVAL_LAST_BLOCK		(-1)
+#define RETVAL_NOT_BZIP_DATA		(-2)
+#define RETVAL_UNEXPECTED_INPUT_EOF	(-3)
+#define RETVAL_UNEXPECTED_OUTPUT_EOF	(-4)
+#define RETVAL_DATA_ERROR		(-5)
+#define RETVAL_OUT_OF_MEMORY		(-6)
+#define RETVAL_OBSOLETE_INPUT		(-7)
+
+
+/* This is what we know about each Huffman coding group */
+struct group_data {
+	/* We have an extra slot at the end of limit[] for a sentinal value. */
+	int limit[MAX_HUFCODE_BITS+1];
+	int base[MAX_HUFCODE_BITS];
+	int permute[MAX_SYMBOLS];
+	int minLen, maxLen;
+};
+
+/* Structure holding all the housekeeping data, including IO buffers and
+   memory that persists between calls to bunzip */
+struct bunzip_data {
+	/* State for interrupting output loop */
+	int writeCopies, writePos, writeRunCountdown, writeCount, writeCurrent;
+	/* I/O tracking data (file handles, buffers, positions, etc.) */
+	int (*fill)(void*, unsigned int);
+	int inbufCount, inbufPos /*, outbufPos*/;
+	unsigned char *inbuf /*,*outbuf*/;
+	unsigned int inbufBitCount, inbufBits;
+	/* The CRC values stored in the block header and calculated from the
+	data */
+	unsigned int crc32Table[256], headerCRC, totalCRC, writeCRC;
+	/* Intermediate buffer and its size (in bytes) */
+	unsigned int *dbuf, dbufSize;
+	/* These things are a bit too big to go on the stack */
+	unsigned char selectors[32768];		/* nSelectors = 15 bits */
+	struct group_data groups[MAX_GROUPS];	/* Huffman coding tables */
+	int io_error;			/* non-zero if we have IO error */
+};
+
+
+/* Return the next nnn bits of input.  All reads from the compressed input
+   are done through this function.  All reads are big endian */
+static unsigned int INIT get_bits(struct bunzip_data *bd, char bits_wanted)
+{
+	unsigned int bits = 0;
+
+	/* If we need to get more data from the byte buffer, do so.
+	   (Loop getting one byte at a time to enforce endianness and avoid
+	   unaligned access.) */
+	while (bd->inbufBitCount < bits_wanted) {
+		/* If we need to read more data from file into byte buffer, do
+		   so */
+		if (bd->inbufPos == bd->inbufCount) {
+			if (bd->io_error)
+				return 0;
+			bd->inbufCount = bd->fill(bd->inbuf, BZIP2_IOBUF_SIZE);
+			if (bd->inbufCount <= 0) {
+				bd->io_error = RETVAL_UNEXPECTED_INPUT_EOF;
+				return 0;
+			}
+			bd->inbufPos = 0;
+		}
+		/* Avoid 32-bit overflow (dump bit buffer to top of output) */
+		if (bd->inbufBitCount >= 24) {
+			bits = bd->inbufBits&((1 << bd->inbufBitCount)-1);
+			bits_wanted -= bd->inbufBitCount;
+			bits <<= bits_wanted;
+			bd->inbufBitCount = 0;
+		}
+		/* Grab next 8 bits of input from buffer. */
+		bd->inbufBits = (bd->inbufBits << 8)|bd->inbuf[bd->inbufPos++];
+		bd->inbufBitCount += 8;
+	}
+	/* Calculate result */
+	bd->inbufBitCount -= bits_wanted;
+	bits |= (bd->inbufBits >> bd->inbufBitCount)&((1 << bits_wanted)-1);
+
+	return bits;
+}
+
+/* Unpacks the next block and sets up for the inverse burrows-wheeler step. */
+
+static int INIT get_next_block(struct bunzip_data *bd)
+{
+	struct group_data *hufGroup = NULL;
+	int *base = NULL;
+	int *limit = NULL;
+	int dbufCount, nextSym, dbufSize, groupCount, selector,
+		i, j, k, t, runPos, symCount, symTotal, nSelectors,
+		byteCount[256];
+	unsigned char uc, symToByte[256], mtfSymbol[256], *selectors;
+	unsigned int *dbuf, origPtr;
+
+	dbuf = bd->dbuf;
+	dbufSize = bd->dbufSize;
+	selectors = bd->selectors;
+
+	/* Read in header signature and CRC, then validate signature.
+	   (last block signature means CRC is for whole file, return now) */
+	i = get_bits(bd, 24);
+	j = get_bits(bd, 24);
+	bd->headerCRC = get_bits(bd, 32);
+	if ((i == 0x177245) && (j == 0x385090))
+		return RETVAL_LAST_BLOCK;
+	if ((i != 0x314159) || (j != 0x265359))
+		return RETVAL_NOT_BZIP_DATA;
+	/* We can add support for blockRandomised if anybody complains.
+	   There was some code for this in busybox 1.0.0-pre3, but nobody ever
+	   noticed that it didn't actually work. */
+	if (get_bits(bd, 1))
+		return RETVAL_OBSOLETE_INPUT;
+	origPtr = get_bits(bd, 24);
+	if (origPtr > dbufSize)
+		return RETVAL_DATA_ERROR;
+	/* mapping table: if some byte values are never used (encoding things
+	   like ascii text), the compression code removes the gaps to have fewer
+	   symbols to deal with, and writes a sparse bitfield indicating which
+	   values were present.  We make a translation table to convert the
+	   symbols back to the corresponding bytes. */
+	t = get_bits(bd, 16);
+	symTotal = 0;
+	for (i = 0; i < 16; i++) {
+		if (t&(1 << (15-i))) {
+			k = get_bits(bd, 16);
+			for (j = 0; j < 16; j++)
+				if (k&(1 << (15-j)))
+					symToByte[symTotal++] = (16*i)+j;
+		}
+	}
+	/* How many different Huffman coding groups does this block use? */
+	groupCount = get_bits(bd, 3);
+	if (groupCount < 2 || groupCount > MAX_GROUPS)
+		return RETVAL_DATA_ERROR;
+	/* nSelectors: Every GROUP_SIZE many symbols we select a new
+	   Huffman coding group.  Read in the group selector list,
+	   which is stored as MTF encoded bit runs.  (MTF = Move To
+	   Front, as each value is used it's moved to the start of the
+	   list.) */
+	nSelectors = get_bits(bd, 15);
+	if (!nSelectors)
+		return RETVAL_DATA_ERROR;
+	for (i = 0; i < groupCount; i++)
+		mtfSymbol[i] = i;
+	for (i = 0; i < nSelectors; i++) {
+		/* Get next value */
+		for (j = 0; get_bits(bd, 1); j++)
+			if (j >= groupCount)
+				return RETVAL_DATA_ERROR;
+		/* Decode MTF to get the next selector */
+		uc = mtfSymbol[j];
+		for (; j; j--) mtfSymbol[j] = mtfSymbol[j-1];
+		mtfSymbol[0] = selectors[i] = uc;
+	}
+	/* Read the Huffman coding tables for each group, which code
+	   for symTotal literal symbols, plus two run symbols (RUNA,
+	   RUNB) */
+	symCount = symTotal+2;
+	for (j = 0; j < groupCount; j++) {
+		unsigned char length[MAX_SYMBOLS], temp[MAX_HUFCODE_BITS+1];
+		int	minLen,	maxLen, pp;
+		/* Read Huffman code lengths for each symbol.  They're
+		   stored in a way similar to mtf; record a starting
+		   value for the first symbol, and an offset from the
+		   previous value for everys symbol after that.
+		   (Subtracting 1 before the loop and then adding it
+		   back at the end is an optimization that makes the
+		   test inside the loop simpler: symbol length 0
+		   becomes negative, so an unsigned inequality catches
+		   it.) */
+		t = get_bits(bd, 5)-1;
+		for (i = 0; i < symCount; i++) {
+			for (;;) {
+				if (((unsigned)t) > (MAX_HUFCODE_BITS-1))
+					return RETVAL_DATA_ERROR;
+
+				/* If first bit is 0, stop.  Else
+				   second bit indicates whether to
+				   increment or decrement the value.
+				   Optimization: grab 2 bits and unget
+				   the second if the first was 0. */
+
+				k = get_bits(bd, 2);
+				if (k < 2) {
+					bd->inbufBitCount++;
+					break;
+				}
+				/* Add one if second bit 1, else
+				 * subtract 1.  Avoids if/else */
+				t += (((k+1)&2)-1);
+			}
+			/* Correct for the initial -1, to get the
+			 * final symbol length */
+			length[i] = t+1;
+		}
+		/* Find largest and smallest lengths in this group */
+		minLen = maxLen = length[0];
+
+		for (i = 1; i < symCount; i++) {
+			if (length[i] > maxLen)
+				maxLen = length[i];
+			else if (length[i] < minLen)
+				minLen = length[i];
+		}
+
+		/* Calculate permute[], base[], and limit[] tables from
+		 * length[].
+		 *
+		 * permute[] is the lookup table for converting
+		 * Huffman coded symbols into decoded symbols.  base[]
+		 * is the amount to subtract from the value of a
+		 * Huffman symbol of a given length when using
+		 * permute[].
+		 *
+		 * limit[] indicates the largest numerical value a
+		 * symbol with a given number of bits can have.  This
+		 * is how the Huffman codes can vary in length: each
+		 * code with a value > limit[length] needs another
+		 * bit.
+		 */
+		hufGroup = bd->groups+j;
+		hufGroup->minLen = minLen;
+		hufGroup->maxLen = maxLen;
+		/* Note that minLen can't be smaller than 1, so we
+		   adjust the base and limit array pointers so we're
+		   not always wasting the first entry.  We do this
+		   again when using them (during symbol decoding).*/
+		base = hufGroup->base-1;
+		limit = hufGroup->limit-1;
+		/* Calculate permute[].  Concurently, initialize
+		 * temp[] and limit[]. */
+		pp = 0;
+		for (i = minLen; i <= maxLen; i++) {
+			temp[i] = limit[i] = 0;
+			for (t = 0; t < symCount; t++)
+				if (length[t] == i)
+					hufGroup->permute[pp++] = t;
+		}
+		/* Count symbols coded for at each bit length */
+		for (i = 0; i < symCount; i++) temp[length[i]]++;
+		/* Calculate limit[] (the largest symbol-coding value
+		 *at each bit length, which is (previous limit <<
+		 *1)+symbols at this level), and base[] (number of
+		 *symbols to ignore at each bit length, which is limit
+		 *minus the cumulative count of symbols coded for
+		 *already). */
+		pp = t = 0;
+		for (i = minLen; i < maxLen; i++) {
+			pp += temp[i];
+			/* We read the largest possible symbol size
+			   and then unget bits after determining how
+			   many we need, and those extra bits could be
+			   set to anything.  (They're noise from
+			   future symbols.)  At each level we're
+			   really only interested in the first few
+			   bits, so here we set all the trailing
+			   to-be-ignored bits to 1 so they don't
+			   affect the value > limit[length]
+			   comparison. */
+			limit[i] = (pp << (maxLen - i)) - 1;
+			pp <<= 1;
+			base[i+1] = pp-(t += temp[i]);
+		}
+		limit[maxLen+1] = INT_MAX; /* Sentinal value for
+					    * reading next sym. */
+		limit[maxLen] = pp+temp[maxLen]-1;
+		base[minLen] = 0;
+	}
+	/* We've finished reading and digesting the block header.  Now
+	   read this block's Huffman coded symbols from the file and
+	   undo the Huffman coding and run length encoding, saving the
+	   result into dbuf[dbufCount++] = uc */
+
+	/* Initialize symbol occurrence counters and symbol Move To
+	 * Front table */
+	for (i = 0; i < 256; i++) {
+		byteCount[i] = 0;
+		mtfSymbol[i] = (unsigned char)i;
+	}
+	/* Loop through compressed symbols. */
+	runPos = dbufCount = symCount = selector = 0;
+	for (;;) {
+		/* Determine which Huffman coding group to use. */
+		if (!(symCount--)) {
+			symCount = GROUP_SIZE-1;
+			if (selector >= nSelectors)
+				return RETVAL_DATA_ERROR;
+			hufGroup = bd->groups+selectors[selector++];
+			base = hufGroup->base-1;
+			limit = hufGroup->limit-1;
+		}
+		/* Read next Huffman-coded symbol. */
+		/* Note: It is far cheaper to read maxLen bits and
+		   back up than it is to read minLen bits and then an
+		   additional bit at a time, testing as we go.
+		   Because there is a trailing last block (with file
+		   CRC), there is no danger of the overread causing an
+		   unexpected EOF for a valid compressed file.  As a
+		   further optimization, we do the read inline
+		   (falling back to a call to get_bits if the buffer
+		   runs dry).  The following (up to got_huff_bits:) is
+		   equivalent to j = get_bits(bd, hufGroup->maxLen);
+		 */
+		while (bd->inbufBitCount < hufGroup->maxLen) {
+			if (bd->inbufPos == bd->inbufCount) {
+				j = get_bits(bd, hufGroup->maxLen);
+				goto got_huff_bits;
+			}
+			bd->inbufBits =
+				(bd->inbufBits << 8)|bd->inbuf[bd->inbufPos++];
+			bd->inbufBitCount += 8;
+		};
+		bd->inbufBitCount -= hufGroup->maxLen;
+		j = (bd->inbufBits >> bd->inbufBitCount)&
+			((1 << hufGroup->maxLen)-1);
+got_huff_bits:
+		/* Figure how how many bits are in next symbol and
+		 * unget extras */
+		i = hufGroup->minLen;
+		while (j > limit[i])
+			++i;
+		bd->inbufBitCount += (hufGroup->maxLen - i);
+		/* Huffman decode value to get nextSym (with bounds checking) */
+		if ((i > hufGroup->maxLen)
+			|| (((unsigned)(j = (j>>(hufGroup->maxLen-i))-base[i]))
+				>= MAX_SYMBOLS))
+			return RETVAL_DATA_ERROR;
+		nextSym = hufGroup->permute[j];
+		/* We have now decoded the symbol, which indicates
+		   either a new literal byte, or a repeated run of the
+		   most recent literal byte.  First, check if nextSym
+		   indicates a repeated run, and if so loop collecting
+		   how many times to repeat the last literal. */
+		if (((unsigned)nextSym) <= SYMBOL_RUNB) { /* RUNA or RUNB */
+			/* If this is the start of a new run, zero out
+			 * counter */
+			if (!runPos) {
+				runPos = 1;
+				t = 0;
+			}
+			/* Neat trick that saves 1 symbol: instead of
+			   or-ing 0 or 1 at each bit position, add 1
+			   or 2 instead.  For example, 1011 is 1 << 0
+			   + 1 << 1 + 2 << 2.  1010 is 2 << 0 + 2 << 1
+			   + 1 << 2.  You can make any bit pattern
+			   that way using 1 less symbol than the basic
+			   or 0/1 method (except all bits 0, which
+			   would use no symbols, but a run of length 0
+			   doesn't mean anything in this context).
+			   Thus space is saved. */
+			t += (runPos << nextSym);
+			/* +runPos if RUNA; +2*runPos if RUNB */
+
+			runPos <<= 1;
+			continue;
+		}
+		/* When we hit the first non-run symbol after a run,
+		   we now know how many times to repeat the last
+		   literal, so append that many copies to our buffer
+		   of decoded symbols (dbuf) now.  (The last literal
+		   used is the one at the head of the mtfSymbol
+		   array.) */
+		if (runPos) {
+			runPos = 0;
+			if (dbufCount+t >= dbufSize)
+				return RETVAL_DATA_ERROR;
+
+			uc = symToByte[mtfSymbol[0]];
+			byteCount[uc] += t;
+			while (t--)
+				dbuf[dbufCount++] = uc;
+		}
+		/* Is this the terminating symbol? */
+		if (nextSym > symTotal)
+			break;
+		/* At this point, nextSym indicates a new literal
+		   character.  Subtract one to get the position in the
+		   MTF array at which this literal is currently to be
+		   found.  (Note that the result can't be -1 or 0,
+		   because 0 and 1 are RUNA and RUNB.  But another
+		   instance of the first symbol in the mtf array,
+		   position 0, would have been handled as part of a
+		   run above.  Therefore 1 unused mtf position minus 2
+		   non-literal nextSym values equals -1.) */
+		if (dbufCount >= dbufSize)
+			return RETVAL_DATA_ERROR;
+		i = nextSym - 1;
+		uc = mtfSymbol[i];
+		/* Adjust the MTF array.  Since we typically expect to
+		 *move only a small number of symbols, and are bound
+		 *by 256 in any case, using memmove here would
+		 *typically be bigger and slower due to function call
+		 *overhead and other assorted setup costs. */
+		do {
+			mtfSymbol[i] = mtfSymbol[i-1];
+		} while (--i);
+		mtfSymbol[0] = uc;
+		uc = symToByte[uc];
+		/* We have our literal byte.  Save it into dbuf. */
+		byteCount[uc]++;
+		dbuf[dbufCount++] = (unsigned int)uc;
+	}
+	/* At this point, we've read all the Huffman-coded symbols
+	   (and repeated runs) for this block from the input stream,
+	   and decoded them into the intermediate buffer.  There are
+	   dbufCount many decoded bytes in dbuf[].  Now undo the
+	   Burrows-Wheeler transform on dbuf.  See
+	   http://dogma.net/markn/articles/bwt/bwt.htm
+	 */
+	/* Turn byteCount into cumulative occurrence counts of 0 to n-1. */
+	j = 0;
+	for (i = 0; i < 256; i++) {
+		k = j+byteCount[i];
+		byteCount[i] = j;
+		j = k;
+	}
+	/* Figure out what order dbuf would be in if we sorted it. */
+	for (i = 0; i < dbufCount; i++) {
+		uc = (unsigned char)(dbuf[i] & 0xff);
+		dbuf[byteCount[uc]] |= (i << 8);
+		byteCount[uc]++;
+	}
+	/* Decode first byte by hand to initialize "previous" byte.
+	   Note that it doesn't get output, and if the first three
+	   characters are identical it doesn't qualify as a run (hence
+	   writeRunCountdown = 5). */
+	if (dbufCount) {
+		if (origPtr >= dbufCount)
+			return RETVAL_DATA_ERROR;
+		bd->writePos = dbuf[origPtr];
+		bd->writeCurrent = (unsigned char)(bd->writePos&0xff);
+		bd->writePos >>= 8;
+		bd->writeRunCountdown = 5;
+	}
+	bd->writeCount = dbufCount;
+
+	return RETVAL_OK;
+}
+
+/* Undo burrows-wheeler transform on intermediate buffer to produce output.
+   If start_bunzip was initialized with out_fd =-1, then up to len bytes of
+   data are written to outbuf.  Return value is number of bytes written or
+   error (all errors are negative numbers).  If out_fd!=-1, outbuf and len
+   are ignored, data is written to out_fd and return is RETVAL_OK or error.
+*/
+
+static int INIT read_bunzip(struct bunzip_data *bd, char *outbuf, int len)
+{
+	const unsigned int *dbuf;
+	int pos, xcurrent, previous, gotcount;
+
+	/* If last read was short due to end of file, return last block now */
+	if (bd->writeCount < 0)
+		return bd->writeCount;
+
+	gotcount = 0;
+	dbuf = bd->dbuf;
+	pos = bd->writePos;
+	xcurrent = bd->writeCurrent;
+
+	/* We will always have pending decoded data to write into the output
+	   buffer unless this is the very first call (in which case we haven't
+	   Huffman-decoded a block into the intermediate buffer yet). */
+
+	if (bd->writeCopies) {
+		/* Inside the loop, writeCopies means extra copies (beyond 1) */
+		--bd->writeCopies;
+		/* Loop outputting bytes */
+		for (;;) {
+			/* If the output buffer is full, snapshot
+			 * state and return */
+			if (gotcount >= len) {
+				bd->writePos = pos;
+				bd->writeCurrent = xcurrent;
+				bd->writeCopies++;
+				return len;
+			}
+			/* Write next byte into output buffer, updating CRC */
+			outbuf[gotcount++] = xcurrent;
+			bd->writeCRC = (((bd->writeCRC) << 8)
+				^bd->crc32Table[((bd->writeCRC) >> 24)
+				^xcurrent]);
+			/* Loop now if we're outputting multiple
+			 * copies of this byte */
+			if (bd->writeCopies) {
+				--bd->writeCopies;
+				continue;
+			}
+decode_next_byte:
+			if (!bd->writeCount--)
+				break;
+			/* Follow sequence vector to undo
+			 * Burrows-Wheeler transform */
+			previous = xcurrent;
+			pos = dbuf[pos];
+			xcurrent = pos&0xff;
+			pos >>= 8;
+			/* After 3 consecutive copies of the same
+			   byte, the 4th is a repeat count.  We count
+			   down from 4 instead *of counting up because
+			   testing for non-zero is faster */
+			if (--bd->writeRunCountdown) {
+				if (xcurrent != previous)
+					bd->writeRunCountdown = 4;
+			} else {
+				/* We have a repeated run, this byte
+				 * indicates the count */
+				bd->writeCopies = xcurrent;
+				xcurrent = previous;
+				bd->writeRunCountdown = 5;
+				/* Sometimes there are just 3 bytes
+				 * (run length 0) */
+				if (!bd->writeCopies)
+					goto decode_next_byte;
+				/* Subtract the 1 copy we'd output
+				 * anyway to get extras */
+				--bd->writeCopies;
+			}
+		}
+		/* Decompression of this block completed successfully */
+		bd->writeCRC = ~bd->writeCRC;
+		bd->totalCRC = ((bd->totalCRC << 1) |
+				(bd->totalCRC >> 31)) ^ bd->writeCRC;
+		/* If this block had a CRC error, force file level CRC error. */
+		if (bd->writeCRC != bd->headerCRC) {
+			bd->totalCRC = bd->headerCRC+1;
+			return RETVAL_LAST_BLOCK;
+		}
+	}
+
+	/* Refill the intermediate buffer by Huffman-decoding next
+	 * block of input */
+	/* (previous is just a convenient unused temp variable here) */
+	previous = get_next_block(bd);
+	if (previous) {
+		bd->writeCount = previous;
+		return (previous != RETVAL_LAST_BLOCK) ? previous : gotcount;
+	}
+	bd->writeCRC = 0xffffffffUL;
+	pos = bd->writePos;
+	xcurrent = bd->writeCurrent;
+	goto decode_next_byte;
+}
+
+static int INIT nofill(void *buf, unsigned int len)
+{
+	return -1;
+}
+
+/* Allocate the structure, read file header.  If in_fd ==-1, inbuf must contain
+   a complete bunzip file (len bytes long).  If in_fd!=-1, inbuf and len are
+   ignored, and data is read from file handle into temporary buffer. */
+static int INIT start_bunzip(struct bunzip_data **bdp, void *inbuf, int len,
+			     int (*fill)(void*, unsigned int))
+{
+	struct bunzip_data *bd;
+	unsigned int i, j, c;
+	const unsigned int BZh0 =
+		(((unsigned int)'B') << 24)+(((unsigned int)'Z') << 16)
+		+(((unsigned int)'h') << 8)+(unsigned int)'0';
+
+	/* Figure out how much data to allocate */
+	i = sizeof(struct bunzip_data);
+
+	/* Allocate bunzip_data.  Most fields initialize to zero. */
+	bd = *bdp = malloc(i);
+	memset(bd, 0, sizeof(struct bunzip_data));
+	/* Setup input buffer */
+	bd->inbuf = inbuf;
+	bd->inbufCount = len;
+	if (fill != NULL)
+		bd->fill = fill;
+	else
+		bd->fill = nofill;
+
+	/* Init the CRC32 table (big endian) */
+	for (i = 0; i < 256; i++) {
+		c = i << 24;
+		for (j = 8; j; j--)
+			c = c&0x80000000 ? (c << 1)^0x04c11db7 : (c << 1);
+		bd->crc32Table[i] = c;
+	}
+
+	/* Ensure that file starts with "BZh['1'-'9']." */
+	i = get_bits(bd, 32);
+	if (((unsigned int)(i-BZh0-1)) >= 9)
+		return RETVAL_NOT_BZIP_DATA;
+
+	/* Fourth byte (ascii '1'-'9'), indicates block size in units of 100k of
+	   uncompressed data.  Allocate intermediate buffer for block. */
+	bd->dbufSize = 100000*(i-BZh0);
+
+	bd->dbuf = large_malloc(bd->dbufSize * sizeof(int));
+	return RETVAL_OK;
+}
+
+/* Example usage: decompress src_fd to dst_fd.  (Stops at end of bzip data,
+   not end of file.) */
+STATIC int INIT bunzip2(char *inbuf, int len,
+			int(*fill)(void*, unsigned int),
+#ifdef IN_MEMORY
+			unsigned char *outpuf,
+#else
+			int(*flush)(void*, unsigned int),
+#endif
+			int *pos)
+{
+	struct bunzip_data *bd;
+	int i;
+#ifndef IN_MEMORY
+	char *outbuf = malloc(BZIP2_IOBUF_SIZE);
+#endif
+	i = start_bunzip(&bd, inbuf, len, fill);
+	if (!i) {
+		for (;;) {
+			i = read_bunzip(bd, outbuf, BZIP2_IOBUF_SIZE);
+			if (i <= 0)
+				break;
+#ifdef IN_MEMORY
+			outbuf += i;
+#else
+			if (i != flush(outbuf, i)) {
+				i = RETVAL_UNEXPECTED_OUTPUT_EOF;
+				break;
+			}
+#endif
+		}
+	}
+	/* Check CRC and release memory */
+	if (i == RETVAL_LAST_BLOCK) {
+		if (bd->headerCRC != bd->totalCRC)
+			error("Data integrity error when decompressing.");
+		else
+			i = RETVAL_OK;
+	} else if (i == RETVAL_UNEXPECTED_OUTPUT_EOF) {
+		error("Compressed file ends unexpectedly");
+	}
+	if (bd->dbuf)
+		large_free(bd->dbuf);
+	if (pos)
+		*pos = bd->inbufPos;
+	free(bd);
+#ifndef IN_MEMORY
+	free(outbuf);
+#endif
+	return i;
+}
+
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/lib/decompress_unlzma.c linux-2.6.26.3udpcast/lib/decompress_unlzma.c
--- linux-2.6.26.3/lib/decompress_unlzma.c	1970-01-01 01:00:00.000000000 +0100
+++ linux-2.6.26.3udpcast/lib/decompress_unlzma.c	2008-09-06 21:31:22.000000000 +0200
@@ -0,0 +1,681 @@
+/* Lzma decompressor for Linux kernel. Shamelessly snarfed
+ *from busybox 1.1.1
+ *
+ *Linux kernel adaptation
+ *Copyright (C) 2006  Alain < alain@knaff.lu >
+ *
+ *Based on small lzma deflate implementation/Small range coder
+ *implementation for lzma.
+ *Copyright (C) 2006  Aurelien Jacobs < aurel@gnuage.org >
+ *
+ *Based on LzmaDecode.c from the LZMA SDK 4.22 (http://www.7-zip.org/)
+ *Copyright (C) 1999-2005  Igor Pavlov
+ *
+ *Copyrights of the parts, see headers below.
+ *
+ *
+ *This program is free software; you can redistribute it and/or
+ *modify it under the terms of the GNU Lesser General Public
+ *License as published by the Free Software Foundation; either
+ *version 2.1 of the License, or (at your option) any later version.
+ *
+ *This program is distributed in the hope that it will be useful,
+ *but WITHOUT ANY WARRANTY; without even the implied warranty of
+ *MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
+ *Lesser General Public License for more details.
+ *
+ *You should have received a copy of the GNU Lesser General Public
+ *License along with this library; if not, write to the Free Software
+ *Foundation, Inc., 51 Franklin St, Fifth Floor, Boston, MA  02110-1301  USA
+ */
+
+#ifndef STATIC
+
+#include <linux/kernel.h>
+#include <linux/fs.h>
+#include <linux/string.h>
+
+#ifdef TEST
+#include "test.h"
+#else
+#include <linux/vmalloc.h>
+#endif
+
+static void __init *large_malloc(size_t size)
+{
+	return vmalloc(size);
+}
+
+static void __init large_free(void *where)
+{
+	vfree(where);
+}
+
+#ifndef TEST
+
+#if 0
+static void __init *malloc(size_t size)
+{
+	return kmalloc(size, GFP_KERNEL);
+}
+#endif
+
+static void __init free(void *where)
+{
+	kfree(where);
+}
+
+static void __init error(char *x)
+{
+	printk(KERN_ERR "%s\n", x);
+}
+
+#endif
+
+#define STATIC /**/
+
+#endif
+
+#ifndef INIT
+#define INIT
+#endif
+
+#include <linux/decompress_unlzma.h>
+
+#define	MIN(a, b) (((a) < (b))?(a):(b))
+
+static long long INIT read_int(unsigned char *ptr, int size)
+{
+	int i;
+	long long ret = 0;
+
+	for (i = 0; i < size; i++)
+		ret = (ret << 8) | ptr[size-i-1];
+	return ret;
+}
+
+#define ENDIAN_CONVERT(x) \
+  x = (typeof(x))read_int((unsigned char *)&x, sizeof(x))
+
+
+/* Small range coder implementation for lzma.
+ *Copyright (C) 2006  Aurelien Jacobs < aurel@gnuage.org >
+ *
+ *Based on LzmaDecode.c from the LZMA SDK 4.22 (http://www.7-zip.org/)
+ *Copyright (c) 1999-2005  Igor Pavlov
+ */
+
+#ifndef always_inline
+#  if defined(__GNUC__) && (__GNUC__ > 3 || __GNUC__ == 3 && __GNUC_MINOR__ > 0)
+#    define always_inline __attribute__((always_inline)) inline
+#  else
+#    define always_inline inline
+#  endif
+#endif
+
+#ifdef CONFIG_FEATURE_LZMA_FAST
+#  define speed_inline always_inline
+#else
+#  define speed_inline
+#endif
+
+
+struct rc {
+	int (*fill)(void*, unsigned int);
+	uint8_t *ptr;
+	uint8_t *buffer;
+	uint8_t *buffer_end;
+	int buffer_size;
+	uint32_t code;
+	uint32_t range;
+	uint32_t bound;
+};
+
+
+#define RC_TOP_BITS 24
+#define RC_MOVE_BITS 5
+#define RC_MODEL_TOTAL_BITS 11
+
+
+/* Called twice: once at startup and once in rc_normalize() */
+static void INIT rc_read(struct rc *rc)
+{
+	rc->buffer_size = rc->fill((char *)rc->buffer, LZMA_IOBUF_SIZE);
+	if (rc->buffer_size <= 0)
+		error("unexpected EOF");
+	rc->ptr = rc->buffer;
+	rc->buffer_end = rc->buffer + rc->buffer_size;
+}
+
+/* Called once */
+static always_inline void INIT rc_init(struct rc *rc,
+				       int (*fill)(void*, unsigned int),
+				       char *buffer, int buffer_size)
+{
+	rc->fill = fill;
+	rc->buffer = (uint8_t *)buffer;
+	rc->buffer_size = buffer_size;
+	rc->buffer_end = rc->buffer + rc->buffer_size;
+	rc->ptr = rc->buffer;
+
+	rc->code = 0;
+	rc->range = 0xFFFFFFFF;
+}
+
+static always_inline void INIT rc_init_code(struct rc *rc)
+{
+	int i;
+
+	for (i = 0; i < 5; i++) {
+		if (rc->ptr >= rc->buffer_end)
+			rc_read(rc);
+		rc->code = (rc->code << 8) | *rc->ptr++;
+	}
+}
+
+
+/* Called once. TODO: bb_maybe_free() */
+static always_inline void INIT rc_free(struct rc *rc)
+{
+	free(rc->buffer);
+}
+
+/* Called twice, but one callsite is in speed_inline'd rc_is_bit_0_helper() */
+static void INIT rc_do_normalize(struct rc *rc)
+{
+	if (rc->ptr >= rc->buffer_end)
+		rc_read(rc);
+	rc->range <<= 8;
+	rc->code = (rc->code << 8) | *rc->ptr++;
+}
+static always_inline void INIT rc_normalize(struct rc *rc)
+{
+	if (rc->range < (1 << RC_TOP_BITS))
+		rc_do_normalize(rc);
+}
+
+/* Called 9 times */
+/* Why rc_is_bit_0_helper exists?
+ *Because we want to always expose (rc->code < rc->bound) to optimizer
+ */
+static speed_inline uint32_t INIT rc_is_bit_0_helper(struct rc *rc, uint16_t *p)
+{
+	rc_normalize(rc);
+	rc->bound = *p * (rc->range >> RC_MODEL_TOTAL_BITS);
+	return rc->bound;
+}
+static always_inline int INIT rc_is_bit_0(struct rc *rc, uint16_t *p)
+{
+	uint32_t t = rc_is_bit_0_helper(rc, p);
+	return rc->code < t;
+}
+
+/* Called ~10 times, but very small, thus inlined */
+static speed_inline void INIT rc_update_bit_0(struct rc *rc, uint16_t *p)
+{
+	rc->range = rc->bound;
+	*p += ((1 << RC_MODEL_TOTAL_BITS) - *p) >> RC_MOVE_BITS;
+}
+static speed_inline void rc_update_bit_1(struct rc *rc, uint16_t *p)
+{
+	rc->range -= rc->bound;
+	rc->code -= rc->bound;
+	*p -= *p >> RC_MOVE_BITS;
+}
+
+/* Called 4 times in unlzma loop */
+static int INIT rc_get_bit(struct rc *rc, uint16_t *p, int *symbol)
+{
+	if (rc_is_bit_0(rc, p)) {
+		rc_update_bit_0(rc, p);
+		*symbol *= 2;
+		return 0;
+	} else {
+		rc_update_bit_1(rc, p);
+		*symbol = *symbol * 2 + 1;
+		return 1;
+	}
+}
+
+/* Called once */
+static always_inline int INIT rc_direct_bit(struct rc *rc)
+{
+	rc_normalize(rc);
+	rc->range >>= 1;
+	if (rc->code >= rc->range) {
+		rc->code -= rc->range;
+		return 1;
+	}
+	return 0;
+}
+
+/* Called twice */
+static speed_inline void INIT
+rc_bit_tree_decode(struct rc *rc, uint16_t *p, int num_levels, int *symbol)
+{
+	int i = num_levels;
+
+	*symbol = 1;
+	while (i--)
+		rc_get_bit(rc, p + *symbol, symbol);
+	*symbol -= 1 << num_levels;
+}
+
+
+/*
+ * Small lzma deflate implementation.
+ * Copyright (C) 2006  Aurelien Jacobs < aurel@gnuage.org >
+ *
+ * Based on LzmaDecode.c from the LZMA SDK 4.22 (http://www.7-zip.org/)
+ * Copyright (C) 1999-2005  Igor Pavlov
+ */
+
+
+struct lzma_header {
+	uint8_t pos;
+	uint32_t dict_size;
+	uint64_t dst_size;
+} __attribute__ ((packed)) ;
+
+
+#define LZMA_BASE_SIZE 1846
+#define LZMA_LIT_SIZE 768
+
+#define LZMA_NUM_POS_BITS_MAX 4
+
+#define LZMA_LEN_NUM_LOW_BITS 3
+#define LZMA_LEN_NUM_MID_BITS 3
+#define LZMA_LEN_NUM_HIGH_BITS 8
+
+#define LZMA_LEN_CHOICE 0
+#define LZMA_LEN_CHOICE_2 (LZMA_LEN_CHOICE + 1)
+#define LZMA_LEN_LOW (LZMA_LEN_CHOICE_2 + 1)
+#define LZMA_LEN_MID (LZMA_LEN_LOW \
+		      + (1 << (LZMA_NUM_POS_BITS_MAX + LZMA_LEN_NUM_LOW_BITS)))
+#define LZMA_LEN_HIGH (LZMA_LEN_MID \
+		       +(1 << (LZMA_NUM_POS_BITS_MAX + LZMA_LEN_NUM_MID_BITS)))
+#define LZMA_NUM_LEN_PROBS (LZMA_LEN_HIGH + (1 << LZMA_LEN_NUM_HIGH_BITS))
+
+#define LZMA_NUM_STATES 12
+#define LZMA_NUM_LIT_STATES 7
+
+#define LZMA_START_POS_MODEL_INDEX 4
+#define LZMA_END_POS_MODEL_INDEX 14
+#define LZMA_NUM_FULL_DISTANCES (1 << (LZMA_END_POS_MODEL_INDEX >> 1))
+
+#define LZMA_NUM_POS_SLOT_BITS 6
+#define LZMA_NUM_LEN_TO_POS_STATES 4
+
+#define LZMA_NUM_ALIGN_BITS 4
+
+#define LZMA_MATCH_MIN_LEN 2
+
+#define LZMA_IS_MATCH 0
+#define LZMA_IS_REP (LZMA_IS_MATCH + (LZMA_NUM_STATES << LZMA_NUM_POS_BITS_MAX))
+#define LZMA_IS_REP_G0 (LZMA_IS_REP + LZMA_NUM_STATES)
+#define LZMA_IS_REP_G1 (LZMA_IS_REP_G0 + LZMA_NUM_STATES)
+#define LZMA_IS_REP_G2 (LZMA_IS_REP_G1 + LZMA_NUM_STATES)
+#define LZMA_IS_REP_0_LONG (LZMA_IS_REP_G2 + LZMA_NUM_STATES)
+#define LZMA_POS_SLOT (LZMA_IS_REP_0_LONG \
+		       + (LZMA_NUM_STATES << LZMA_NUM_POS_BITS_MAX))
+#define LZMA_SPEC_POS (LZMA_POS_SLOT \
+		       +(LZMA_NUM_LEN_TO_POS_STATES << LZMA_NUM_POS_SLOT_BITS))
+#define LZMA_ALIGN (LZMA_SPEC_POS \
+		    + LZMA_NUM_FULL_DISTANCES - LZMA_END_POS_MODEL_INDEX)
+#define LZMA_LEN_CODER (LZMA_ALIGN + (1 << LZMA_NUM_ALIGN_BITS))
+#define LZMA_REP_LEN_CODER (LZMA_LEN_CODER + LZMA_NUM_LEN_PROBS)
+#define LZMA_LITERAL (LZMA_REP_LEN_CODER + LZMA_NUM_LEN_PROBS)
+
+
+struct writer {
+	uint8_t *buffer;
+	uint8_t previous_byte;
+	size_t buffer_pos;
+#ifndef IN_MEMORY
+	int bufsize;
+	size_t global_pos;
+	int(*flush)(void*, unsigned int);
+#endif
+	struct lzma_header *header;
+};
+
+struct cstate {
+	int state;
+	uint32_t rep0, rep1, rep2, rep3;
+};
+
+static always_inline size_t INIT get_pos(struct writer *wr)
+{
+	return
+#ifndef IN_MEMORY
+		wr->global_pos +
+#endif
+		wr->buffer_pos;
+}
+
+static always_inline uint8_t INIT peek_old_byte(struct writer *wr,
+						uint32_t offs)
+{
+#ifdef IN_MEMORY
+	while (offs > wr->header->dict_size)
+		offs -= wr->header->dict_size;
+	int32_t pos = wr->buffer_pos - offs;
+#else
+	uint32_t pos = wr->buffer_pos - offs;
+	while (pos >= wr->header->dict_size)
+		pos += wr->header->dict_size;
+#endif
+	return wr->buffer[pos];
+
+}
+
+static always_inline void INIT write_byte(struct writer *wr, uint8_t byte)
+{
+	wr->buffer[wr->buffer_pos++] = wr->previous_byte = byte;
+#ifndef IN_MEMORY
+	if (wr->buffer_pos == wr->header->dict_size) {
+		wr->buffer_pos = 0;
+		wr->global_pos += wr->header->dict_size;
+		wr->flush((char *)wr->buffer, wr->header->dict_size);
+	}
+#endif
+}
+
+
+static always_inline void INIT copy_byte(struct writer *wr, uint32_t offs)
+{
+	write_byte(wr, peek_old_byte(wr, offs));
+}
+
+static always_inline void INIT copy_bytes(struct writer *wr,
+					 uint32_t rep0, int len)
+{
+	do {
+		copy_byte(wr, rep0);
+		len--;
+	} while (len != 0 && wr->buffer_pos < wr->header->dst_size);
+}
+
+static always_inline void INIT process_bit0(struct writer *wr, struct rc *rc,
+				     struct cstate *cst, uint16_t *p,
+				     int pos_state, uint16_t *prob,
+				     int lc, uint32_t literal_pos_mask) {
+	int mi = 1;
+	rc_update_bit_0(rc, prob);
+	prob = (p + LZMA_LITERAL +
+		(LZMA_LIT_SIZE
+		 * (((get_pos(wr) & literal_pos_mask) << lc)
+		    + (wr->previous_byte >> (8 - lc))))
+		);
+
+	if (cst->state >= LZMA_NUM_LIT_STATES) {
+		int match_byte = peek_old_byte(wr, cst->rep0);
+		do {
+			int bit;
+			uint16_t *prob_lit;
+
+			match_byte <<= 1;
+			bit = match_byte & 0x100;
+			prob_lit = prob + 0x100 + bit + mi;
+			if (rc_get_bit(rc, prob_lit, &mi)) {
+				if (!bit)
+					break;
+			} else {
+				if (bit)
+					break;
+			}
+		} while (mi < 0x100);
+	}
+	while (mi < 0x100) {
+		uint16_t *prob_lit = prob + mi;
+		rc_get_bit(rc, prob_lit, &mi);
+	}
+	write_byte(wr, mi);
+	if (cst->state < 4)
+		cst->state = 0;
+	else if (cst->state < 10)
+		cst->state -= 3;
+	else
+		cst->state -= 6;
+}
+
+static always_inline void INIT process_bit1(struct writer *wr, struct rc *rc,
+					    struct cstate *cst, uint16_t *p,
+					    int pos_state, uint16_t *prob) {
+  int offset;
+	uint16_t *prob_len;
+	int num_bits;
+	int len;
+
+	rc_update_bit_1(rc, prob);
+	prob = p + LZMA_IS_REP + cst->state;
+	if (rc_is_bit_0(rc, prob)) {
+		rc_update_bit_0(rc, prob);
+		cst->rep3 = cst->rep2;
+		cst->rep2 = cst->rep1;
+		cst->rep1 = cst->rep0;
+		cst->state = cst->state < LZMA_NUM_LIT_STATES ? 0 : 3;
+		prob = p + LZMA_LEN_CODER;
+	} else {
+		rc_update_bit_1(rc, prob);
+		prob = p + LZMA_IS_REP_G0 + cst->state;
+		if (rc_is_bit_0(rc, prob)) {
+			rc_update_bit_0(rc, prob);
+			prob = (p + LZMA_IS_REP_0_LONG
+				+ (cst->state <<
+				   LZMA_NUM_POS_BITS_MAX) +
+				pos_state);
+			if (rc_is_bit_0(rc, prob)) {
+				rc_update_bit_0(rc, prob);
+
+				cst->state = cst->state < LZMA_NUM_LIT_STATES ?
+					9 : 11;
+				copy_byte(wr, cst->rep0);
+				return;
+			} else {
+				rc_update_bit_1(rc, prob);
+			}
+		} else {
+			uint32_t distance;
+
+			rc_update_bit_1(rc, prob);
+			prob = p + LZMA_IS_REP_G1 + cst->state;
+			if (rc_is_bit_0(rc, prob)) {
+				rc_update_bit_0(rc, prob);
+				distance = cst->rep1;
+			} else {
+				rc_update_bit_1(rc, prob);
+				prob = p + LZMA_IS_REP_G2 + cst->state;
+				if (rc_is_bit_0(rc, prob)) {
+					rc_update_bit_0(rc, prob);
+					distance = cst->rep2;
+				} else {
+					rc_update_bit_1(rc, prob);
+					distance = cst->rep3;
+					cst->rep3 = cst->rep2;
+				}
+				cst->rep2 = cst->rep1;
+			}
+			cst->rep1 = cst->rep0;
+			cst->rep0 = distance;
+		}
+		cst->state = cst->state < LZMA_NUM_LIT_STATES ? 8 : 11;
+		prob = p + LZMA_REP_LEN_CODER;
+	}
+
+	prob_len = prob + LZMA_LEN_CHOICE;
+	if (rc_is_bit_0(rc, prob_len)) {
+		rc_update_bit_0(rc, prob_len);
+		prob_len = (prob + LZMA_LEN_LOW
+			    + (pos_state <<
+			       LZMA_LEN_NUM_LOW_BITS));
+		offset = 0;
+		num_bits = LZMA_LEN_NUM_LOW_BITS;
+	} else {
+		rc_update_bit_1(rc, prob_len);
+		prob_len = prob + LZMA_LEN_CHOICE_2;
+		if (rc_is_bit_0(rc, prob_len)) {
+			rc_update_bit_0(rc, prob_len);
+			prob_len = (prob + LZMA_LEN_MID
+				    + (pos_state <<
+				       LZMA_LEN_NUM_MID_BITS));
+			offset = 1 << LZMA_LEN_NUM_LOW_BITS;
+			num_bits = LZMA_LEN_NUM_MID_BITS;
+		} else {
+			rc_update_bit_1(rc, prob_len);
+			prob_len = prob + LZMA_LEN_HIGH;
+			offset = ((1 << LZMA_LEN_NUM_LOW_BITS)
+				  + (1 << LZMA_LEN_NUM_MID_BITS));
+			num_bits = LZMA_LEN_NUM_HIGH_BITS;
+		}
+	}
+
+	rc_bit_tree_decode(rc, prob_len, num_bits, &len);
+	len += offset;
+
+	if (cst->state < 4) {
+		int pos_slot;
+
+		cst->state += LZMA_NUM_LIT_STATES;
+		prob =
+			p + LZMA_POS_SLOT +
+			((len <
+			  LZMA_NUM_LEN_TO_POS_STATES ? len :
+			  LZMA_NUM_LEN_TO_POS_STATES - 1)
+			 << LZMA_NUM_POS_SLOT_BITS);
+		rc_bit_tree_decode(rc, prob,
+				   LZMA_NUM_POS_SLOT_BITS,
+				   &pos_slot);
+		if (pos_slot >= LZMA_START_POS_MODEL_INDEX) {
+			int i, mi;
+			num_bits = (pos_slot >> 1) - 1;
+			cst->rep0 = 2 | (pos_slot & 1);
+			if (pos_slot < LZMA_END_POS_MODEL_INDEX) {
+				cst->rep0 <<= num_bits;
+				prob = p + LZMA_SPEC_POS +
+					cst->rep0 - pos_slot - 1;
+			} else {
+				num_bits -= LZMA_NUM_ALIGN_BITS;
+				while (num_bits--)
+					cst->rep0 = (cst->rep0 << 1) |
+						rc_direct_bit(rc);
+				prob = p + LZMA_ALIGN;
+				cst->rep0 <<= LZMA_NUM_ALIGN_BITS;
+				num_bits = LZMA_NUM_ALIGN_BITS;
+			}
+			i = 1;
+			mi = 1;
+			while (num_bits--) {
+				if (rc_get_bit(rc, prob + mi, &mi))
+					cst->rep0 |= i;
+				i <<= 1;
+			}
+		} else
+			cst->rep0 = pos_slot;
+		if (++(cst->rep0) == 0)
+			return;
+	}
+
+	len += LZMA_MATCH_MIN_LEN;
+
+	copy_bytes(wr, cst->rep0, len);
+}
+
+
+
+STATIC always_inline int INIT unlzma(char *inbuf, int in_len,
+				     int(*fill)(void*, unsigned int),
+#ifdef IN_MEMORY
+				     unsigned char *output,
+#else
+				     int(*flush)(void*, unsigned int),
+#endif
+				     int *posp
+)
+{
+	struct lzma_header header;
+	int lc, pb, lp;
+	uint32_t pos_state_mask;
+	uint32_t literal_pos_mask;
+	uint16_t *p;
+	int num_probs;
+	struct rc rc;
+	int i, mi;
+	struct writer wr;
+	struct cstate cst;
+
+	cst.state = 0;
+	cst.rep0 = cst.rep1 = cst.rep2 = cst.rep3 = 1;
+
+	wr.header = &header;
+#ifndef IN_MEMORY
+	wr.flush = flush;
+	wr.global_pos = 0;
+#endif
+	wr.previous_byte = 0;
+	wr.buffer_pos = 0;
+
+	rc_init(&rc, fill, inbuf, in_len);
+
+	for (i = 0; i < sizeof(header); i++) {
+		if (rc.ptr >= rc.buffer_end)
+			rc_read(&rc);
+		((unsigned char *)&header)[i] = *rc.ptr++;
+	}
+
+	if (header.pos >= (9 * 5 * 5))
+		error("bad header");
+
+	mi = header.pos / 9;
+	lc = header.pos % 9;
+	pb = mi / 5;
+	lp = mi % 5;
+	pos_state_mask = (1 << pb) - 1;
+	literal_pos_mask = (1 << lp) - 1;
+
+	ENDIAN_CONVERT(header.dict_size);
+	ENDIAN_CONVERT(header.dst_size);
+
+	if (header.dict_size == 0)
+		header.dict_size = 1;
+
+#ifdef IN_MEMORY
+	wr.buffer = output;
+#else
+	wr.bufsize = MIN(header.dst_size, header.dict_size);
+	wr.buffer = large_malloc(wr.bufsize);
+#endif
+	if (wr.buffer == NULL)
+		return -1;
+
+	num_probs = LZMA_BASE_SIZE + (LZMA_LIT_SIZE << (lc + lp));
+	p = large_malloc(num_probs * sizeof(*p));
+	num_probs = LZMA_LITERAL + (LZMA_LIT_SIZE << (lc + lp));
+	for (i = 0; i < num_probs; i++)
+		p[i] = (1 << RC_MODEL_TOTAL_BITS) >> 1;
+
+	rc_init_code(&rc);
+
+	while (get_pos(&wr) < header.dst_size) {
+		int pos_state =	get_pos(&wr) & pos_state_mask;
+		uint16_t *prob = p + LZMA_IS_MATCH +
+			(cst.state << LZMA_NUM_POS_BITS_MAX) + pos_state;
+		if (rc_is_bit_0(&rc, prob))
+			process_bit0(&wr, &rc, &cst, p, pos_state, prob,
+				     lc, literal_pos_mask);
+		else {
+			process_bit1(&wr, &rc, &cst, p, pos_state, prob);
+			if (cst.rep0 == 0)
+				break;
+		}
+	}
+
+#ifndef IN_MEMORY
+	wr.flush(wr.buffer, wr.buffer_pos);
+	large_free(wr.buffer);
+#endif
+	if (posp)
+		*posp = rc.ptr-rc.buffer;
+	large_free(p);
+	return 0;
+}
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/lib/Makefile linux-2.6.26.3udpcast/lib/Makefile
--- linux-2.6.26.3/lib/Makefile	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/lib/Makefile	2008-09-03 19:47:02.000000000 +0200
@@ -51,6 +51,10 @@ obj-$(CONFIG_CRC7)	+= crc7.o
 obj-$(CONFIG_LIBCRC32C)	+= libcrc32c.o
 obj-$(CONFIG_GENERIC_ALLOCATOR) += genalloc.o
 
+obj-$(CONFIG_RD_BZIP2)	+= decompress_bunzip2.o
+obj-$(CONFIG_RD_LZMA)	+= decompress_unlzma.o
+
+
 obj-$(CONFIG_ZLIB_INFLATE) += zlib_inflate/
 obj-$(CONFIG_ZLIB_DEFLATE) += zlib_deflate/
 obj-$(CONFIG_REED_SOLOMON) += reed_solomon/
diff -purN -X linux-2.6.26.3udpcast/Documentation/dontdiff linux-2.6.26.3/scripts/Makefile.lib linux-2.6.26.3udpcast/scripts/Makefile.lib
--- linux-2.6.26.3/scripts/Makefile.lib	2008-08-20 20:11:37.000000000 +0200
+++ linux-2.6.26.3udpcast/scripts/Makefile.lib	2008-09-06 21:33:15.000000000 +0200
@@ -173,3 +173,17 @@ quiet_cmd_gzip = GZIP    $@
 cmd_gzip = gzip -f -9 < $< > $@
 
 
+# Bzip2
+# ---------------------------------------------------------------------------
+
+# Bzip2 does not include size in file... so we have to fake that
+size_append=perl -e 'print(pack("i",(stat($$ARGV[0]))[7]));'
+
+quiet_cmd_bzip2 = BZIP2    $@
+cmd_bzip2 = (bzip2 -9 < $< ; $(size_append) $<) > $@
+
+# Lzma
+# ---------------------------------------------------------------------------
+
+quiet_cmd_lzma = LZMA    $@
+cmd_lzma = lzma --format=alone -9 -c $< >$@
