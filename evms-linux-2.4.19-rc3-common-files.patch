diff -Naur linux-2002-07-24/Documentation/Configure.help evms-2002-07-24/Documentation/Configure.help
--- linux-2002-07-24/Documentation/Configure.help	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/Documentation/Configure.help	Wed Jul 24 09:09:30 2002
@@ -1755,6 +1755,196 @@
   called on26.o. You must also have a high-level driver for the type
   of device that you want to support.
 
+EVMS Kernel Runtime
+CONFIG_EVMS
+  EVMS runtime driver. This is a plugin-based framework for volume
+  management, and combines support for partitioning, software RAID,
+  LVM, and more into a single interface.
+
+  User-space tools are required to perform administration of EVMS logical
+  volumes. Please visit <http://www.sourceforge.net/projects/evms> for
+  more details on downloading and installing these tools.
+
+  This driver is also available as a pair of modules called evms.o and
+  evms_passthru.o ( = code which can be inserted and removed from the
+  running kernel whenever you want). If you want to compile it as a module,
+  say M here and read <file:Documentation/modules.txt>.
+
+EVMS Local Device Manager Plugin
+CONFIG_EVMS_LOCAL_DEV_MGR_PLUGIN
+  Support for local IDE and SCSI devices. This plugin is required if EVMS
+  support is selected.
+
+  This plugin is also available as a kernel module called ldev_mgr.o.
+
+EVMS DOS Partition Manager Plugin
+CONFIG_EVMS_DOS_PARTITION_PLUGIN
+  Support for recognizing all partitions using the ever-popular DOS
+  partitioning scheme (MBRs & EBRs). 99% of the time you will need 
+  this plugin to do anything useful with EVMS.
+
+  This plugin also contains support for recognizing BSD disklabels,
+  UNIXWARE partitions, Solaris-X86 partitions, and OS/2 DLAT entries.
+
+  This plugin is also available as a kernel module called dos_part.o.
+
+EVMS GPT Partition Manager Plugin
+CONFIG_EVMS_GPT_PARTITION_PLUGIN
+  Support for recognizing all partitions using the new EFI GUID partitioning
+  scheme that is used by IA-64 machines. You should only need to enable this
+  plugin if you are running Linux on an IA-64 machine. All other architectures
+  can say 'N' here.
+
+  This plugin is also available as a kernel module called gpt_part.o
+
+EVMS S/390 Partition Manager Plugin
+CONFIG_EVMS_S390_PART_PLUGIN
+  Support for recognizing all partitions created on S/390 machines. This
+  plugin recognizes CDL, LDL, and CMS partition formats. You should only need
+  to enable this plugin if you are running Linux on an S/390. All other
+  architectures can say 'N' here.
+
+  This plugin is also available as a kernel module called s390_part.o
+
+EVMS SnapShot Feature Plugin
+CONFIG_EVMS_SNAPSHOT_PLUGIN
+  This feature plugin lets you create a snapshot of any volume
+  under EVMS control using any other device under under EVMS
+  control as the target for the snapshot volume.
+
+  This plugin is also available as a kernel module called snapshot.o.
+
+EVMS DriveLink Feature Plugin
+CONFIG_EVMS_DRIVELINK_PLUGIN
+  This feature plugin lets you combine multiple devices into a
+  single virtual block device. The size of the virtual block
+  device is approximately equal to the sum of all its components.
+  It currently supports combining up to 60 devices (partitions,
+  disks, or logical volumes).
+
+  This plugin is also available as a kernel module called evms_drivelink.o.
+
+EVMS Bad Block Relocation (BBR) Feature
+CONFIG_EVMS_BBR_PLUGIN
+  BBR is designed to remap I/O write failures to another safe
+  location on disk. Note that most disk drives have BBR built
+  into them, so software BBR will only be activated when all
+  hardware BBR replacement sectors have been used.
+
+  This plugin is also available as a kernel module called evms_bbr.o.
+
+EVMS Linux LVM Plugin
+CONFIG_EVMS_LVM_PLUGIN
+  The LVM plugin is responsible for providing compatibility with the Linux
+  LVM. This plugin recognizes disks and partitions that are LVM physical
+  volumes (PVs), and assembles the appropriate volume groups (VGs). LVM
+  logical volumes (LVs) are exported as EVMS volumes with full read/write
+  support.  In addition, support for striped and snapshotted volumes is
+  included. The corresponding EVMS Engine plugin must also be installed in
+  order to perform any administration of LVM VGs and LVs.
+
+  This plugin is also available as a kernel module called lvm_vge.o.
+
+EVMS MD Plugin
+CONFIG_EVMS_MD_PLUGIN
+  The MD plugin is responsible for providing compatibility with the Linux
+  Software RAID driver (MD). It allows several devices to be combined into
+  one logical device. This can be used to simply append one disk or
+  partition to another, or to combine several redundant disks into a
+  RAID 1/4/5 device so as to provide protection against hard disk failures.
+
+  This plugin is also available as a kernel module called md_core.o.
+
+EVMS MD RAID-Linear Plugin
+CONFIG_EVMS_MD_LINEAR_PERS
+  The RAID-Linear personality combines disks and/or partitions simply by
+  appending one to the other.
+
+  This plugin is also available as a kernel module called md_linear.o.
+
+EVMS MD RAID-0 Plugin
+CONFIG_EVMS_MD_RAID0_PERS
+  The RAID-0 personality combines disks and/or partitions into one
+  logical device using striping. This method writes data evenly across
+  all members in the device in order to increase the throughput rate if
+  each member resides on a distinct disk.
+
+  This plugin is also available as a kernel module called md_raid0.o.
+
+EVMS MD RAID-1 Plugin
+CONFIG_EVMS_MD_RAID1_PERS
+  The RAID-1 personality implements mirroring, in which a logical device
+  consists of several disks that are exact copies of each other. In the
+  event of a mirror failure, the RAID-1 personality will continue to use
+  the remaining mirrors in the set, providing an error free device to the
+  higher levels of the kernel. In a set with N drives, the available space
+  is the capacity of a single drive, and the set protects against the
+  failure of N-1 drives.
+
+  This plugin is also available as a kernel module called md_raid1.o.
+
+EVMS MD RAID-4/RAID-5 Plugin
+CONFIG_EVMS_MD_RAID5_PERS
+  A RAID-5 set of N drives with a capacity of C MB per drive provides
+  the capacity of C * (N-1) MB, and protects against a failure of a
+  single drive. For a given sector (row) number, (N-1) drives contain
+  data sectors, and one drive contains the parity protection. For a
+  RAID-4 set, the parity blocks are present on a single drive, while
+  a RAID-5 set distributes the parity across all drives in one of the
+  available parity distribution methods.
+
+  This plugin is also available as a kernel module called md_raid5.o.
+
+EVMS AIX LVM Plugin
+CONFIG_EVMS_AIX_PLUGIN
+  The AIX LVM plugin is responsible for providing compatibility with the
+  AIX LVM. This plugin recognizes disks and partitions that are AIX disks,
+  and assembles the appropriate volume groups. AIX logical volumes are
+  exported as EVMS volumes with full read/write support. In addition,
+  support for striped volumes is included, and support for mirroring is
+  under development.
+
+  You should only need to select this option if you are running on a PPC
+  machine and want to access AIX LVM volumes. The user-space plugin for
+  AIX will be available in the future.
+
+  This plugin is also available as a kernel module called AIXlvm_vge.o.
+
+EVMS OS/2 LVM Plugin
+CONFIG_EVMS_OS2_PLUGIN
+  Support for recognizing the type 0x35 partitions that later versions
+  of OS/2 use in its Logical Volume Manager.  Provides binary
+  compatibility and includes Drive Linking and Bad Block Relocation
+  emulation. The user-space plugin for OS/2 will be available in the future.
+
+  This plugin is also available as a kernel module called os2lvm_vge.o.
+
+EVMS Clustering Plugin
+CONFIG_EVMS_ECR_PLUGIN
+
+  The EVMS Clustering Plugin is still under design and development.
+  Best to just say 'n' here.
+
+  This plugin is available as a kernel module called evms_ecr.o.
+
+EVMS Debug Level
+CONFIG_EVMS_INFO_CRITICAL
+  Set the level for kernel messages from EVMS. Each level on the list
+  produces message for that level and all levels above it. Thus, level
+  "Critical" only logs the most critical messages (and thus the fewest),
+  whereas level "Everything" produces more information that will probably
+  ever be useful.  Level "Default" is a good starting point. Level "Debug"
+  is good if you are having problems with EVMS and want more basic info
+  on what's going on during the volume discovery process.
+
+  EVMS also supports a boot-time kernel parameter to set the info level.
+  To use this method, specify "evms_info_level=5" at boot time, or add the
+  line "append = "evms_info_level=5"" to your lilo.conf file (replacing 5
+  with your desired info level). See include/linux/evms/evms.h for the
+  numerical definitions of the info levels. To use this boot-time parameter,
+  the EVMS core driver must be statically built into the kernel (not as a
+  module).
+
 Logical Volume Manager (LVM) support
 CONFIG_BLK_DEV_LVM
   This driver lets you combine several hard disks, hard disk
diff -Naur linux-2002-07-24/MAINTAINERS evms-2002-07-24/MAINTAINERS
--- linux-2002-07-24/MAINTAINERS	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/MAINTAINERS	Wed Jul 24 09:08:21 2002
@@ -533,6 +533,13 @@
 W:	http://opensource.creative.com/
 S:	Maintained
 
+ENTERPRISE VOLUME MANAGEMENT SYSTEM (EVMS)
+P:	Mark Peloquin, Steve Pratt, Kevin Corry
+M:	peloquin@us.ibm.com, slpratt@us.ibm.com, corryk@us.ibm.com
+L:	evms-devel@lists.sourceforge.net                          
+W:	http://www.sourceforge.net/projects/evms/
+S:	Supported
+
 ETHEREXPRESS-16 NETWORK DRIVER
 P:	Philip Blundell
 M:	Philip.Blundell@pobox.com
diff -Naur linux-2002-07-24/Makefile evms-2002-07-24/Makefile
--- linux-2002-07-24/Makefile	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/Makefile	Wed Jul 24 09:08:53 2002
@@ -188,6 +188,7 @@
 DRIVERS-$(CONFIG_BLUEZ) += drivers/bluetooth/bluetooth.o
 DRIVERS-$(CONFIG_HOTPLUG_PCI) += drivers/hotplug/vmlinux-obj.o
 DRIVERS-$(CONFIG_ISDN_BOOL) += drivers/isdn/vmlinux-obj.o
+DRIVERS-$(CONFIG_EVMS) += drivers/evms/evmsdrvr.o
 
 DRIVERS := $(DRIVERS-y)
 
diff -Naur linux-2002-07-24/arch/i386/config.in evms-2002-07-24/arch/i386/config.in
--- linux-2002-07-24/arch/i386/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/i386/config.in	Wed Jun  5 16:07:45 2002
@@ -301,6 +301,8 @@
 
 source drivers/block/Config.in
 
+source drivers/evms/Config.in
+
 source drivers/md/Config.in
 
 if [ "$CONFIG_NET" = "y" ]; then
diff -Naur linux-2002-07-24/arch/ia64/config.in evms-2002-07-24/arch/ia64/config.in
--- linux-2002-07-24/arch/ia64/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/ia64/config.in	Wed Jun  5 16:07:56 2002
@@ -137,6 +137,7 @@
 source drivers/block/Config.in
 source drivers/ieee1394/Config.in
 source drivers/message/i2o/Config.in
+source drivers/evms/Config.in
 source drivers/md/Config.in
 
 mainmenu_option next_comment
diff -Naur linux-2002-07-24/arch/parisc/config.in evms-2002-07-24/arch/parisc/config.in
--- linux-2002-07-24/arch/parisc/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/parisc/config.in	Mon Mar 11 13:26:56 2002
@@ -106,6 +106,8 @@
 
 source drivers/block/Config.in
 
+source drivers/evms/Config.in
+
 if [ "$CONFIG_NET" = "y" ]; then
   source net/Config.in
 fi
diff -Naur linux-2002-07-24/arch/ppc/config.in evms-2002-07-24/arch/ppc/config.in
--- linux-2002-07-24/arch/ppc/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/ppc/config.in	Wed Jun  5 16:08:20 2002
@@ -245,6 +245,7 @@
 source drivers/mtd/Config.in
 source drivers/pnp/Config.in
 source drivers/block/Config.in
+source drivers/evms/Config.in
 source drivers/md/Config.in
 
 if [ "$CONFIG_NET" = "y" ]; then
diff -Naur linux-2002-07-24/arch/ppc64/config.in evms-2002-07-24/arch/ppc64/config.in
--- linux-2002-07-24/arch/ppc64/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/ppc64/config.in	Tue Jul  2 11:14:31 2002
@@ -100,6 +100,7 @@
 source drivers/mtd/Config.in
 source drivers/pnp/Config.in
 source drivers/block/Config.in
+source drivers/evms/Config.in
 source drivers/md/Config.in
 
 if [ "$CONFIG_NET" = "y" ]; then
diff -Naur linux-2002-07-24/arch/ppc64/kernel/ioctl32.c evms-2002-07-24/arch/ppc64/kernel/ioctl32.c
--- linux-2002-07-24/arch/ppc64/kernel/ioctl32.c	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/ppc64/kernel/ioctl32.c	Tue Jul  2 11:14:31 2002
@@ -3435,6 +3435,383 @@
 	return ((0 == ret) ? 0 : -EFAULT);
 }	
 
+#ifdef CONFIG_EVMS
+
+#include <linux/evms/evms_kernel.h>
+#include <linux/evms/evms_bbr.h>
+
+struct evms_sector_io32 {
+	u64 disk_handle;
+	s32 io_flag;
+	u64 starting_sector;
+	u64 sector_count;
+	__kernel_caddr_t32 buffer_address;
+	s32 status;
+};
+
+struct evms_rediscover32 {
+	s32 status;
+	u32 drive_count;
+	__kernel_caddr_t32 drive_array;
+};
+
+struct evms_compute_csum32 {
+	__kernel_caddr_t32 buffer_address;
+	s32 buffer_size;
+	u32 insum;
+	u32 outsum;
+	s32 status;
+};
+
+struct evms_plugin_ioctl32 {
+	u32 feature_id;
+	s32 feature_command;
+	s32 status;
+	__kernel_caddr_t32 feature_ioctl_data;
+};
+
+struct evms_notify_bbr32 {
+	char object_name[EVMS_VOLUME_NAME_SIZE+1];
+	u64 count;
+	u64 start_sect;
+	u64 nr_sect;
+	__kernel_caddr_t32 buffer;
+	s32 rw;
+};
+
+#define EVMS_MD_ID		4
+#define EVMS_MD_PERS_IOCTL_CMD	1
+#define EVMS_MD_ADD		2
+#define EVMS_MD_REMOVE		3
+#define EVMS_MD_ACTIVATE	4
+#define EVMS_MD_DEACTIVATE	5
+#define EVMS_MD_GET_ARRAY_INFO	6
+#define EVMS_MD_RAID5_INIT_IO	1
+
+struct evms_md_ioctl {
+	int mddev_idx;
+	int cmd;
+	void *arg;
+};
+
+struct evms_md_ioctl32 {
+	u32 mddev_idx;
+	u32 cmd;
+	__kernel_caddr_t32 arg;
+};
+
+struct evms_md_array_info {
+	unsigned long state;
+	mdp_super_t *sb;
+};
+
+struct evms_md_array_info32 {
+	u32 state;
+	__kernel_caddr_t32 sb;
+};
+
+struct raid5_ioctl_init_io {
+	int rw;
+	u64 lsn;
+	u64 nr_sects;
+	void *data;
+};
+
+struct raid5_ioctl_init_io32 {
+	s32 rw;
+	u64 lsn;
+	u64 nr_sects;
+	__kernel_caddr_t32 data;
+};
+
+#define EVMS_MD_PLUGIN_ID	((IBM_OEM_ID << 16) | \
+				 (EVMS_REGION_MANAGER << 12) | EVMS_MD_ID)
+#define EVMS_BBR_PLUGIN_ID	((IBM_OEM_ID << 16) | \
+				 (EVMS_FEATURE << 12) | EVMS_BBR_FEATURE_ID)
+
+
+#define EVMS_SECTOR_IO_32                _IOWR(	EVMS_MAJOR, \
+						EVMS_SECTOR_IO_NUMBER, \
+						struct evms_sector_io32)
+#define EVMS_REDISCOVER_VOLUMES_32       _IOWR(	EVMS_MAJOR, \
+						EVMS_REDISCOVER_VOLUMES_NUMBER, \
+						struct evms_rediscover32)
+#define EVMS_COMPUTE_CSUM_32             _IOWR(	EVMS_MAJOR, \
+						EVMS_COMPUTE_CSUM_NUMBER, \
+						struct evms_compute_csum32)
+#define EVMS_PLUGIN_IOCTL_32             _IOR(	EVMS_MAJOR, \
+						EVMS_PLUGIN_IOCTL_NUMBER, \
+						struct evms_plugin_ioctl32)
+
+static int evms_sector_io(unsigned int fd, unsigned int cmd, unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	struct evms_sector_io32	parms32;
+	struct evms_sector_io parms;
+	unsigned int kcmd;
+	void *karg;
+	int rc = 0;
+
+	if (copy_from_user(&parms32, (struct evms_sector_io32 *)arg,
+			    sizeof(struct evms_sector_io32)))
+		return -EFAULT;
+
+	parms.disk_handle     = parms32.disk_handle;
+	parms.io_flag         = parms32.io_flag;
+	parms.starting_sector = parms32.starting_sector;
+	parms.sector_count    = parms32.sector_count;
+	parms.buffer_address  = (u8 *)A(parms32.buffer_address);
+	parms.status          = 0;
+
+	kcmd = EVMS_SECTOR_IO;
+	karg = &parms;
+
+	set_fs(KERNEL_DS);
+	rc = sys_ioctl(fd, kcmd, (unsigned long)karg);
+	set_fs(old_fs);
+
+	parms32.status = parms.status;
+	parms32.buffer_address = (__kernel_caddr_t32)AA(parms.buffer_address);
+
+	if (copy_to_user((struct evms_sector_io32 *)arg, &parms32,
+			 sizeof(struct evms_sector_io32)))
+		return -EFAULT;
+
+	return rc;
+}
+
+static int evms_rediscover(unsigned int fd, unsigned int cmd, unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	struct evms_rediscover32 parms32;
+	struct evms_rediscover parms;
+	unsigned int kcmd;
+	void *karg;
+	int rc = 0;
+
+	if (copy_from_user(&parms32, (struct evms_rediscover32 *)arg,
+			   sizeof(struct evms_rediscover32)))
+		return -EFAULT;
+
+	parms.drive_count = parms32.drive_count;
+	parms.drive_array = (void *)A(parms32.drive_array);
+	parms.status      = 0;
+
+	kcmd = EVMS_REDISCOVER_VOLUMES;
+	karg = &parms;
+
+	set_fs(KERNEL_DS);
+	rc = sys_ioctl(fd, kcmd, (unsigned long)karg);
+	set_fs(old_fs);
+
+	parms32.status = parms.status;
+
+	if (copy_to_user((struct evms_rediscover32 *)arg, &parms32,
+			 sizeof(struct evms_rediscover32)))
+		return -EFAULT;
+
+	return rc;
+}
+
+static int evms_compute_csum(unsigned int fd,
+			     unsigned int cmd,
+			     unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	struct evms_compute_csum32 parms32;
+	struct evms_compute_csum parms;
+	unsigned int kcmd;
+	void *karg;
+	int rc = 0;
+
+	if (copy_from_user(&parms32, (struct evms_compute_csum32 *)arg,
+			   sizeof(struct evms_compute_csum32)))
+		return -EFAULT;
+
+	parms.insum          = parms32.insum;
+	parms.outsum         = parms32.outsum;
+	parms.buffer_size    = parms32.buffer_size;
+	parms.buffer_address = (void *)A(parms32.buffer_address);
+	parms.status         = 0;
+
+	kcmd = EVMS_COMPUTE_CSUM;
+	karg = &parms;
+
+	set_fs(KERNEL_DS);
+	rc = sys_ioctl(fd, kcmd, (unsigned long)karg);
+	set_fs(old_fs);
+
+	parms32.status = parms.status;
+	parms32.outsum = parms.outsum;
+
+	if (copy_to_user((struct evms_compute_csum32 *)arg, &parms32,
+			 sizeof(struct evms_compute_csum32)))
+		return -EFAULT;
+
+	return rc;
+}
+
+static int evms_bbr_plugin_ioctl(unsigned int fd,
+				 unsigned int cmd,
+				 unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	struct evms_notify_bbr32 bbr_parms32;
+	struct evms_notify_bbr bbr_parms;
+	struct evms_plugin_ioctl *parms = (struct evms_plugin_ioctl *)arg;
+	void *old_ptr = NULL;
+	int rc;
+
+	if (copy_from_user(&bbr_parms32,
+			   (struct evms_notify_bbr32 *)parms->feature_ioctl_data,
+			   sizeof(struct evms_notify_bbr32)))
+		return -EFAULT;
+
+	memcpy(&bbr_parms, &bbr_parms32, sizeof(struct evms_notify_bbr32));
+	bbr_parms.buffer          = (void *)A(bbr_parms32.buffer);
+	bbr_parms.rw              = bbr_parms32.rw;
+	old_ptr                   = parms->feature_ioctl_data;
+	parms->feature_ioctl_data = &bbr_parms;
+
+	set_fs(KERNEL_DS);
+	rc = sys_ioctl(fd, cmd, arg);
+	set_fs(old_fs);
+
+	parms->feature_ioctl_data = old_ptr;
+
+	if (!rc) {
+		bbr_parms32.nr_sect = bbr_parms.nr_sect;
+		rc = copy_to_user((struct evms_notify_bbr32 *)parms->feature_ioctl_data,
+				  &bbr_parms32, sizeof(struct evms_notify_bbr32));
+	}
+
+	return rc;
+}
+
+static int evms_md_plugin_ioctl(unsigned int fd,
+				unsigned int cmd,
+				unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	void *old_ptr = NULL;
+	void *old_md_ptr = NULL;
+	struct evms_md_ioctl32 md_parms32;
+	struct evms_md_ioctl md_parms;
+	struct evms_md_array_info32 md_array_parms32;
+	struct evms_md_array_info md_array_parms;
+	struct raid5_ioctl_init_io32 r5_init_io_parms32;
+	struct raid5_ioctl_init_io r5_init_io_parms;
+	struct evms_plugin_ioctl *parms = (struct evms_plugin_ioctl *)arg;
+	int rc;
+
+	if (copy_from_user(&md_parms32,
+			   (struct evms_md_ioctl*)parms->feature_ioctl_data,
+			   sizeof(struct evms_md_ioctl32)))
+		return -EFAULT;
+
+	md_parms.mddev_idx        = md_parms32.mddev_idx;
+	md_parms.cmd              = md_parms32.cmd;
+	md_parms.arg              = (void *)A(md_parms32.arg);
+	old_ptr                   = parms->feature_ioctl_data;
+	parms->feature_ioctl_data = &md_parms;
+
+	if (parms->feature_command == EVMS_MD_GET_ARRAY_INFO) {
+		if (copy_from_user(&md_array_parms32,
+				   (struct evms_md_array_info32*)md_parms.arg,
+				   sizeof(struct evms_md_array_info32)))
+			return -EFAULT;
+		md_array_parms.state = md_array_parms32.state;
+		md_array_parms.sb    = (void *)A(md_array_parms32.sb);
+		old_md_ptr           = (void *)md_parms.arg;
+		md_parms.arg         = &md_array_parms;
+	} else if (parms->feature_command == EVMS_MD_PERS_IOCTL_CMD) {
+		if (md_parms.cmd == EVMS_MD_RAID5_INIT_IO) {
+			if (copy_from_user(&r5_init_io_parms32,
+					   (struct raid5_ioctl_init_io32*)md_parms.arg,
+					   sizeof(struct raid5_ioctl_init_io32)))
+				return -EFAULT;
+
+			r5_init_io_parms.rw       = r5_init_io_parms32.rw;
+			r5_init_io_parms.lsn      = r5_init_io_parms32.lsn;
+			r5_init_io_parms.nr_sects = r5_init_io_parms32.nr_sects;
+			r5_init_io_parms.data     = (void *)A(r5_init_io_parms32.data);
+			old_md_ptr                = (void *)md_parms.arg;
+			md_parms.arg              = &r5_init_io_parms;
+		}
+	}
+
+	set_fs(KERNEL_DS);
+	rc = sys_ioctl(fd, cmd, arg);
+	set_fs(old_fs);
+
+	parms->feature_ioctl_data = old_ptr;
+	md_parms.arg              = old_md_ptr;
+
+	if (!rc) {
+		if (parms->feature_command == EVMS_MD_GET_ARRAY_INFO) {
+			md_array_parms32.state = md_array_parms.state;
+			rc = copy_to_user((struct evms_md_array_info32 *)md_parms.arg,
+					  &md_array_parms32,
+					  sizeof(struct evms_md_array_info32));
+		}
+		if (!rc) {
+			md_parms32.mddev_idx = md_parms.mddev_idx;
+			rc = copy_to_user((struct evms_md_ioctl*)parms->feature_ioctl_data,
+					  &md_parms32,
+					  sizeof(struct evms_md_ioctl32));
+		}
+	}
+
+	return rc;
+}
+
+static int evms_plugin_ioctl(unsigned int fd,
+			     unsigned int cmd,
+			     unsigned long arg)
+{
+	mm_segment_t old_fs = get_fs();
+	struct evms_plugin_ioctl32 parms32;
+	struct evms_plugin_ioctl parms;
+	unsigned int kcmd;
+	void *karg;
+	int rc;
+
+	if (copy_from_user(&parms32, (struct evms_plugin_ioctl32 *)arg,
+			   sizeof(struct evms_plugin_ioctl32)))
+		return -EFAULT;
+
+	parms.feature_id         = parms32.feature_id;
+	parms.feature_command    = parms32.feature_command;
+	parms.status             = parms32.status;
+	parms.feature_ioctl_data = (void *)A(parms32.feature_ioctl_data);
+
+	kcmd = EVMS_PLUGIN_IOCTL;
+	karg = &parms;
+
+	switch (parms.feature_id) {
+	case EVMS_MD_PLUGIN_ID:
+		rc = evms_md_plugin_ioctl(fd, kcmd, (unsigned long)karg);
+		break;
+	case EVMS_BBR_PLUGIN_ID:
+		rc = evms_bbr_plugin_ioctl(fd, kcmd, (unsigned long)karg);
+		break;
+	default:
+		set_fs(KERNEL_DS);
+		rc = sys_ioctl(fd, kcmd, (unsigned long)karg);
+		set_fs(old_fs);
+	}
+
+	if (!rc) {
+		parms32.status = parms.status;
+		rc = copy_to_user((struct evms_plugin_ioctl32 *)arg, &parms32,
+				  sizeof(struct evms_plugin_ioctl32));
+	}
+
+	return rc;
+}
+
+#endif
+
 struct sg_io_hdr_32
 {
 	int interface_id;
@@ -4092,6 +4469,29 @@
 COMPATIBLE_IOCTL(ATMTCP_REMOVE),
 COMPATIBLE_IOCTL(ATMMPC_CTRL),
 COMPATIBLE_IOCTL(ATMMPC_DATA),
+
+#ifdef CONFIG_EVMS
+COMPATIBLE_IOCTL(EVMS_GET_INFO_LEVEL),
+COMPATIBLE_IOCTL(EVMS_SET_INFO_LEVEL),
+HANDLE_IOCTL(EVMS_REDISCOVER_VOLUMES_32, evms_rediscover),
+COMPATIBLE_IOCTL(EVMS_DELETE_VOLUME),
+HANDLE_IOCTL(EVMS_PLUGIN_IOCTL_32, evms_plugin_ioctl),
+COMPATIBLE_IOCTL(EVMS_PROCESS_NOTIFY_EVENT),
+COMPATIBLE_IOCTL(EVMS_GET_LOGICAL_DISK),
+COMPATIBLE_IOCTL(EVMS_GET_LOGICAL_DISK_INFO),
+HANDLE_IOCTL(EVMS_SECTOR_IO_32, evms_sector_io),
+COMPATIBLE_IOCTL(EVMS_GET_MINOR),
+COMPATIBLE_IOCTL(EVMS_GET_VOLUME_DATA),
+COMPATIBLE_IOCTL(EVMS_GET_PLUGIN),
+HANDLE_IOCTL(EVMS_COMPUTE_CSUM_32, evms_compute_csum),
+COMPATIBLE_IOCTL(EVMS_GET_BMAP),
+COMPATIBLE_IOCTL(EVMS_GET_IOCTL_VERSION),
+COMPATIBLE_IOCTL(EVMS_GET_VERSION),
+COMPATIBLE_IOCTL(EVMS_UPDATE_DEVICE_INFO),
+COMPATIBLE_IOCTL(EVMS_CHECK_MOUNT_STATUS),
+COMPATIBLE_IOCTL(EVMS_GET_VOL_STRIPE_INFO),
+#endif
+
 #if defined(CONFIG_BLK_DEV_LVM) || defined(CONFIG_BLK_DEV_LVM_MODULE)
 /* 0xfe - lvm */
 COMPATIBLE_IOCTL(VG_SET_EXTENDABLE),
diff -Naur linux-2002-07-24/arch/s390/config.in evms-2002-07-24/arch/s390/config.in
--- linux-2002-07-24/arch/s390/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/s390/config.in	Wed Jun  5 16:08:32 2002
@@ -59,6 +59,8 @@
 
 source drivers/s390/Config.in
 
+source drivers/evms/Config.in
+
 if [ "$CONFIG_NET" = "y" ]; then
   source net/Config.in
 fi
diff -Naur linux-2002-07-24/arch/s390x/config.in evms-2002-07-24/arch/s390x/config.in
--- linux-2002-07-24/arch/s390x/config.in	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/arch/s390x/config.in	Wed Jun  5 16:08:39 2002
@@ -61,6 +61,8 @@
 
 source drivers/s390/Config.in
 
+source drivers/evms/Config.in
+
 if [ "$CONFIG_NET" = "y" ]; then
   source net/Config.in
 fi
diff -Naur linux-2002-07-24/drivers/Makefile evms-2002-07-24/drivers/Makefile
--- linux-2002-07-24/drivers/Makefile	Wed Jul 24 09:15:33 2002
+++ evms-2002-07-24/drivers/Makefile	Wed Jun  5 16:09:04 2002
@@ -8,7 +8,7 @@
 
 mod-subdirs :=	dio mtd sbus video macintosh usb input telephony sgi ide \
 		message/i2o message/fusion scsi md ieee1394 pnp isdn atm \
-		fc4 net/hamradio i2c acpi bluetooth
+		fc4 net/hamradio i2c acpi bluetooth evms
 
 subdir-y :=	parport char block net sound misc media cdrom hotplug
 subdir-m :=	$(subdir-y)
@@ -46,5 +46,6 @@
 subdir-$(CONFIG_ACPI)		+= acpi
 
 subdir-$(CONFIG_BLUEZ)		+= bluetooth
+subdir-$(CONFIG_EVMS)		+= evms
 
 include $(TOPDIR)/Rules.make
diff -Naur linux-2002-07-24/include/linux/fs.h evms-2002-07-24/include/linux/fs.h
--- linux-2002-07-24/include/linux/fs.h	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/include/linux/fs.h	Wed Jul 24 09:12:32 2002
@@ -1472,6 +1472,7 @@
 unsigned long generate_cluster_swab32(kdev_t, int b[], int);
 extern kdev_t ROOT_DEV;
 extern char root_device_name[];
+extern void get_root_device_name( char * root_name );
 
 
 extern void show_buffers(void);
diff -Naur linux-2002-07-24/include/linux/major.h evms-2002-07-24/include/linux/major.h
--- linux-2002-07-24/include/linux/major.h	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/include/linux/major.h	Mon Jul  8 16:23:51 2002
@@ -142,6 +142,8 @@
 
 #define	UMEM_MAJOR	116	/* http://www.umem.com/ Battery Backed RAM */
 
+#define EVMS_MAJOR	117	/* Enterprise Volume Management System */
+
 #define RTF_MAJOR	150
 #define RAW_MAJOR	162
 
diff -Naur linux-2002-07-24/include/linux/mempool.h evms-2002-07-24/include/linux/mempool.h
--- linux-2002-07-24/include/linux/mempool.h	Wed Dec 31 18:00:00 1969
+++ evms-2002-07-24/include/linux/mempool.h	Mon Jun 17 10:13:08 2002
@@ -0,0 +1,30 @@
+/*
+ * memory buffer pool support
+ */
+#ifndef _LINUX_MEMPOOL_H
+#define _LINUX_MEMPOOL_H
+
+#include <linux/wait.h>
+
+typedef void * (mempool_alloc_t)(int gfp_mask, void *pool_data);
+typedef void (mempool_free_t)(void *element, void *pool_data);
+
+typedef struct mempool_s {
+	spinlock_t lock;
+	int min_nr;		/* nr of elements at *elements */
+	int curr_nr;		/* Current nr of elements at *elements */
+	void **elements;
+
+	void *pool_data;
+	mempool_alloc_t *alloc;
+	mempool_free_t *free;
+	wait_queue_head_t wait;
+} mempool_t;
+extern mempool_t * mempool_create(int min_nr, mempool_alloc_t *alloc_fn,
+				 mempool_free_t *free_fn, void *pool_data);
+extern int mempool_resize(mempool_t *pool, int new_min_nr, int gfp_mask);
+extern void mempool_destroy(mempool_t *pool);
+extern void * mempool_alloc(mempool_t *pool, int gfp_mask);
+extern void mempool_free(void *element, mempool_t *pool);
+
+#endif /* _LINUX_MEMPOOL_H */
diff -Naur linux-2002-07-24/include/linux/sysctl.h evms-2002-07-24/include/linux/sysctl.h
--- linux-2002-07-24/include/linux/sysctl.h	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/include/linux/sysctl.h	Wed Jun  5 16:11:50 2002
@@ -556,7 +556,8 @@
 	DEV_HWMON=2,
 	DEV_PARPORT=3,
 	DEV_RAID=4,
-	DEV_MAC_HID=5
+	DEV_MAC_HID=5,
+	DEV_EVMS=6
 };
 
 /* /proc/sys/dev/cdrom */
@@ -572,6 +573,18 @@
 /* /proc/sys/dev/parport */
 enum {
 	DEV_PARPORT_DEFAULT=-3
+};
+
+/* /proc/sys/dev/evms */
+enum {
+	DEV_EVMS_INFO_LEVEL=1,
+	DEV_EVMS_MD=2
+};
+
+/* /proc/sys/dev/evms/raid */
+enum {
+	DEV_EVMS_MD_SPEED_LIMIT_MIN=1,
+	DEV_EVMS_MD_SPEED_LIMIT_MAX=2
 };
 
 /* /proc/sys/dev/raid */
diff -Naur linux-2002-07-24/init/do_mounts.c evms-2002-07-24/init/do_mounts.c
--- linux-2002-07-24/init/do_mounts.c	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/init/do_mounts.c	Wed Jul 24 09:13:46 2002
@@ -224,6 +224,7 @@
 	{ "ftlc", 0x2c10 },
 	{ "ftld", 0x2c18 },
 	{ "mtdblock", 0x1f00 },
+ 	{ "evms", 0x7500 },
 	{ NULL, 0 }
 };
 
@@ -738,6 +739,11 @@
 	}
 #endif
 	mount_block_root("/dev/root", root_mountflags);
+}
+
+void get_root_device_name( char * root_name )
+{
+	strncpy(root_name, root_device_name, 63);
 }
 
 #ifdef CONFIG_BLK_DEV_INITRD
diff -Naur linux-2002-07-24/kernel/ksyms.c evms-2002-07-24/kernel/ksyms.c
--- linux-2002-07-24/kernel/ksyms.c	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/kernel/ksyms.c	Wed Jul 24 09:14:08 2002
@@ -320,6 +320,8 @@
 EXPORT_SYMBOL(refile_buffer);
 EXPORT_SYMBOL(max_sectors);
 EXPORT_SYMBOL(max_readahead);
+EXPORT_SYMBOL(is_swap_partition);
+EXPORT_SYMBOL(walk_gendisk);
 
 /* tty routines */
 EXPORT_SYMBOL(tty_hangup);
diff -Naur linux-2002-07-24/mm/Makefile evms-2002-07-24/mm/Makefile
--- linux-2002-07-24/mm/Makefile	Wed Jul 24 09:15:34 2002
+++ evms-2002-07-24/mm/Makefile	Wed Jun 19 11:21:04 2002
@@ -9,12 +9,12 @@
 
 O_TARGET := mm.o
 
-export-objs := shmem.o filemap.o memory.o page_alloc.o
+export-objs := shmem.o filemap.o memory.o page_alloc.o mempool.o
 
 obj-y	 := memory.o mmap.o filemap.o mprotect.o mlock.o mremap.o \
 	    vmalloc.o slab.o bootmem.o swap.o vmscan.o page_io.o \
 	    page_alloc.o swap_state.o swapfile.o numa.o oom_kill.o \
-	    shmem.o
+	    shmem.o mempool.o
 
 obj-$(CONFIG_HIGHMEM) += highmem.o
 
diff -Naur linux-2002-07-24/mm/mempool.c evms-2002-07-24/mm/mempool.c
--- linux-2002-07-24/mm/mempool.c	Wed Dec 31 18:00:00 1969
+++ evms-2002-07-24/mm/mempool.c	Wed Jun 19 09:47:16 2002
@@ -0,0 +1,273 @@
+/*
+ *  linux/mm/mempool.c
+ *
+ *  memory buffer pool support. Such pools are mostly used
+ *  for guaranteed, deadlock-free memory allocations during
+ *  extreme VM load.
+ *
+ *  started by Ingo Molnar, Copyright (C) 2001
+ */
+
+#include <linux/mm.h>
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/compiler.h>
+#include <linux/mempool.h>
+#include <linux/fs.h>
+
+#define BUG_ON(condition) do { if (unlikely((condition)!=0)) BUG(); } while(0)
+
+static void add_element(mempool_t *pool, void *element)
+{
+	BUG_ON(pool->curr_nr >= pool->min_nr);
+	pool->elements[pool->curr_nr++] = element;
+}
+
+static void *remove_element(mempool_t *pool)
+{
+	BUG_ON(pool->curr_nr <= 0);
+	return pool->elements[--pool->curr_nr];
+}
+
+static void free_pool(mempool_t *pool)
+{
+	while (pool->curr_nr) {
+		void *element = remove_element(pool);
+		pool->free(element, pool->pool_data);
+	}
+	kfree(pool->elements);
+	kfree(pool);
+}
+
+/**
+ * mempool_create - create a memory pool
+ * @min_nr:    the minimum number of elements guaranteed to be
+ *             allocated for this pool.
+ * @alloc_fn:  user-defined element-allocation function.
+ * @free_fn:   user-defined element-freeing function.
+ * @pool_data: optional private data available to the user-defined functions.
+ *
+ * this function creates and allocates a guaranteed size, preallocated
+ * memory pool. The pool can be used from the mempool_alloc and mempool_free
+ * functions. This function might sleep. Both the alloc_fn() and the free_fn()
+ * functions might sleep - as long as the mempool_alloc function is not called
+ * from IRQ contexts.
+ */
+mempool_t * mempool_create(int min_nr, mempool_alloc_t *alloc_fn,
+				mempool_free_t *free_fn, void *pool_data)
+{
+	mempool_t *pool;
+
+	pool = kmalloc(sizeof(*pool), GFP_KERNEL);
+	if (!pool)
+		return NULL;
+	memset(pool, 0, sizeof(*pool));
+	pool->elements = kmalloc(min_nr * sizeof(void *), GFP_KERNEL);
+	if (!pool->elements) {
+		kfree(pool);
+		return NULL;
+	}
+	spin_lock_init(&pool->lock);
+	pool->min_nr = min_nr;
+	pool->pool_data = pool_data;
+	init_waitqueue_head(&pool->wait);
+	pool->alloc = alloc_fn;
+	pool->free = free_fn;
+
+	/*
+	 * First pre-allocate the guaranteed number of buffers.
+	 */
+	while (pool->curr_nr < pool->min_nr) {
+		void *element;
+
+		element = pool->alloc(GFP_KERNEL, pool->pool_data);
+		if (unlikely(!element)) {
+			free_pool(pool);
+			return NULL;
+		}
+		add_element(pool, element);
+	}
+	return pool;
+}
+
+/**
+ * mempool_resize - resize an existing memory pool
+ * @pool:       pointer to the memory pool which was allocated via
+ *              mempool_create().
+ * @new_min_nr: the new minimum number of elements guaranteed to be
+ *              allocated for this pool.
+ * @gfp_mask:   the usual allocation bitmask.
+ *
+ * This function shrinks/grows the pool. In the case of growing,
+ * it cannot be guaranteed that the pool will be grown to the new
+ * size immediately, but new mempool_free() calls will refill it.
+ *
+ * Note, the caller must guarantee that no mempool_destroy is called
+ * while this function is running. mempool_alloc() & mempool_free()
+ * might be called (eg. from IRQ contexts) while this function executes.
+ */
+int mempool_resize(mempool_t *pool, int new_min_nr, int gfp_mask)
+{
+	void *element;
+	void **new_elements;
+	unsigned long flags;
+
+	BUG_ON(new_min_nr <= 0);
+
+	spin_lock_irqsave(&pool->lock, flags);
+	if (new_min_nr < pool->min_nr) {
+		while (pool->curr_nr > new_min_nr) {
+			element = remove_element(pool);
+			spin_unlock_irqrestore(&pool->lock, flags);
+			pool->free(element, pool->pool_data);
+			spin_lock_irqsave(&pool->lock, flags);
+		}
+		pool->min_nr = new_min_nr;
+		goto out_unlock;
+	}
+	spin_unlock_irqrestore(&pool->lock, flags);
+
+	/* Grow the pool */
+	new_elements = kmalloc(new_min_nr * sizeof(*new_elements), gfp_mask);
+	if (!new_elements)
+		return -ENOMEM;
+
+	spin_lock_irqsave(&pool->lock, flags);
+	memcpy(new_elements, pool->elements,
+			pool->curr_nr * sizeof(*new_elements));
+	kfree(pool->elements);
+	pool->elements = new_elements;
+	pool->min_nr = new_min_nr;
+
+	while (pool->curr_nr < pool->min_nr) {
+		spin_unlock_irqrestore(&pool->lock, flags);
+		element = pool->alloc(gfp_mask, pool->pool_data);
+		if (!element)
+			goto out;
+		spin_lock_irqsave(&pool->lock, flags);
+		if (pool->curr_nr < pool->min_nr)
+			add_element(pool, element);
+		else
+			kfree(element);		/* Raced */
+	}
+out_unlock:
+	spin_unlock_irqrestore(&pool->lock, flags);
+out:
+	return 0;
+}
+
+/**
+ * mempool_destroy - deallocate a memory pool
+ * @pool:      pointer to the memory pool which was allocated via
+ *             mempool_create().
+ *
+ * this function only sleeps if the free_fn() function sleeps. The caller
+ * has to guarantee that all elements have been returned to the pool (ie:
+ * freed) prior to calling mempool_destroy().
+ */
+void mempool_destroy(mempool_t *pool)
+{
+	if (pool->curr_nr != pool->min_nr)
+		BUG();		/* There were outstanding elements */
+	free_pool(pool);
+}
+
+/**
+ * mempool_alloc - allocate an element from a specific memory pool
+ * @pool:      pointer to the memory pool which was allocated via
+ *             mempool_create().
+ * @gfp_mask:  the usual allocation bitmask.
+ *
+ * this function only sleeps if the alloc_fn function sleeps or
+ * returns NULL. Note that due to preallocation, this function
+ * *never* fails when called from process contexts. (it might
+ * fail if called from an IRQ context.)
+ */
+void * mempool_alloc(mempool_t *pool, int gfp_mask)
+{
+	void *element;
+	unsigned long flags;
+	int curr_nr;
+	DECLARE_WAITQUEUE(wait, current);
+	int gfp_nowait = gfp_mask & ~(__GFP_WAIT | __GFP_IO);
+
+repeat_alloc:
+	element = pool->alloc(gfp_nowait, pool->pool_data);
+	if (likely(element != NULL))
+		return element;
+
+	/*
+	 * If the pool is less than 50% full then try harder
+	 * to allocate an element:
+	 */
+	if ((gfp_mask != gfp_nowait) && (pool->curr_nr <= pool->min_nr/2)) {
+		element = pool->alloc(gfp_mask, pool->pool_data);
+		if (likely(element != NULL))
+			return element;
+	}
+
+	/*
+	 * Kick the VM at this point.
+	 */
+	wakeup_bdflush();
+
+	spin_lock_irqsave(&pool->lock, flags);
+	if (likely(pool->curr_nr)) {
+		element = remove_element(pool);
+		spin_unlock_irqrestore(&pool->lock, flags);
+		return element;
+	}
+	spin_unlock_irqrestore(&pool->lock, flags);
+
+	/* We must not sleep in the GFP_ATOMIC case */
+	if (gfp_mask == gfp_nowait)
+		return NULL;
+
+	run_task_queue(&tq_disk);
+
+	add_wait_queue_exclusive(&pool->wait, &wait);
+	set_task_state(current, TASK_UNINTERRUPTIBLE);
+
+	spin_lock_irqsave(&pool->lock, flags);
+	curr_nr = pool->curr_nr;
+	spin_unlock_irqrestore(&pool->lock, flags);
+
+	if (!curr_nr)
+		schedule();
+
+	current->state = TASK_RUNNING;
+	remove_wait_queue(&pool->wait, &wait);
+
+	goto repeat_alloc;
+}
+
+/**
+ * mempool_free - return an element to the pool.
+ * @element:   pool element pointer.
+ * @pool:      pointer to the memory pool which was allocated via
+ *             mempool_create().
+ *
+ * this function only sleeps if the free_fn() function sleeps.
+ */
+void mempool_free(void *element, mempool_t *pool)
+{
+	unsigned long flags;
+
+	if (pool->curr_nr < pool->min_nr) {
+		spin_lock_irqsave(&pool->lock, flags);
+		if (pool->curr_nr < pool->min_nr) {
+			add_element(pool, element);
+			spin_unlock_irqrestore(&pool->lock, flags);
+			wake_up(&pool->wait);
+			return;
+		}
+		spin_unlock_irqrestore(&pool->lock, flags);
+	}
+	pool->free(element, pool->pool_data);
+}
+
+EXPORT_SYMBOL(mempool_create);
+EXPORT_SYMBOL(mempool_resize);
+EXPORT_SYMBOL(mempool_destroy);
+EXPORT_SYMBOL(mempool_alloc);
+EXPORT_SYMBOL(mempool_free);
