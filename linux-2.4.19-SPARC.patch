--- linux-2.4.19/arch/sparc/kernel/process.c.org	Sat Aug  3 02:39:43 2002
+++ linux-2.4.19/arch/sparc/kernel/process.c	Fri Sep 27 09:34:30 2002
@@ -74,7 +74,6 @@
 		goto out;
 
 	/* endless idle loop with no priority at all */
-	init_idle();
 
 	for (;;) {
 		if (ARCH_SUN4C_SUN4) {
@@ -128,7 +125,6 @@
 int cpu_idle(void)
 {
 	/* endless idle loop with no priority at all */
-	init_idle();
 
 	while(1) {
 		if(current->need_resched) {
--- linux/include/asm-sparc/bitops.h.orig	Tue Aug 21 14:26:16 2001
+++ linux/include/asm-sparc/bitops.h	Fri Jul 19 15:03:33 2002
@@ -330,6 +400,25 @@
 }
 
 #ifdef __KERNEL__
+
+/*
+ * Every architecture must define this function. It's the fastest
+ * way of searching a 140-bit bitmap where the first 100 bits are
+ * unlikely to be set. It's guaranteed that at least one of the 140
+ * bits is cleared.
+ */
+static inline int _sched_find_first_bit(unsigned long *b)
+{
+	if (unlikely(b[0]))
+		return __ffs(b[0]);
+	if (unlikely(b[1]))
+		return __ffs(b[1]) + 32;
+	if (unlikely(b[2]))
+		return __ffs(b[2]) + 64;
+	if (b[3])
+		return __ffs(b[3]) + 96;
+	return __ffs(b[4]) + 128;
+}
 
 /**
  * ffs - find first bit set
--- linux-2.4.19/include/asm-sparc/pgtable.h.org	Mon Sep 23 09:33:03 2002
+++ linux-2.4.19/include/asm-sparc/pgtable.h	Mon Sep 23 10:23:24 2002
@@ -118,6 +118,16 @@
 #define PAGE_COPY      __pgprot(BTFIXUP_INT(page_copy))
 #define PAGE_READONLY  __pgprot(BTFIXUP_INT(page_readonly))
 
+#ifdef CONFIG_GRKERNSEC_PAX
+#define	PAGE_SHARED_NOEXEC	PAGE_SHARED
+#define	PAGE_COPY_NOEXEC	PAGE_COPY
+#define	PAGE_READONLY_NOEXEC	PAGE_READONLY
+#else
+#define	PAGE_SHARED_NOEXEC	PAGE_SHARED
+#define	PAGE_COPY_NOEXEC	PAGE_COPY
+#define	PAGE_READONLY_NOEXEC	PAGE_READONLY
+#endif
+
 extern unsigned long page_kernel;
 
 #ifdef MODULE
--- linux-2.4.19/kernel/sched.c.org	Fri Sep 13 10:27:12 2002
+++ linux-2.4.19/kernel/sched.c	Fri Sep 13 10:12:38 2002
@@ -520,6 +520,11 @@
 {
 	finish_arch_switch(this_rq(), prev);
 }
+#else
+asmlinkage void schedule_tail(task_t *prev)
+{
+	finish_arch_switch(this_rq(), prev);
+}
 #endif
 
 static inline task_t * context_switch(task_t *prev, task_t *next)
