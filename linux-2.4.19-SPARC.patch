--- linux-2.4.19/arch/sparc/kernel/process.c.org	Sat Aug  3 02:39:43 2002
+++ linux-2.4.19/arch/sparc/kernel/process.c	Fri Sep 27 09:34:30 2002
@@ -74,7 +74,6 @@
 		goto out;
 
 	/* endless idle loop with no priority at all */
-	init_idle();
 
 	for (;;) {
 		if (ARCH_SUN4C_SUN4) {
@@ -128,7 +125,6 @@
 int cpu_idle(void)
 {
 	/* endless idle loop with no priority at all */
-	init_idle();
 
 	while(1) {
 		if(current->need_resched) {
--- linux/include/asm-sparc/bitops.h.orig	Tue Aug 21 14:26:16 2001
+++ linux/include/asm-sparc/bitops.h	Fri Jul 19 15:03:33 2002
@@ -13,6 +13,23 @@
 #include <asm/byteorder.h>
 #include <asm/system.h>
 
+/**
+ * __ffs - find first bit in word.
+ * @word: The word to search
+ *
+ * Undefined if no bit exists, so code should check against 0 first.
+ */
+static __inline__ unsigned long __ffs(unsigned long word)
+{
+	unsigned long result = 0;
+
+	while (!(word & 1UL)) {
+		result++;
+		word >>= 1;
+	}
+	return result;
+}
+
 #ifdef __KERNEL__
 
 /*
@@ -330,6 +400,25 @@
 }
 
 #ifdef __KERNEL__
+
+/*
+ * Every architecture must define this function. It's the fastest
+ * way of searching a 140-bit bitmap where the first 100 bits are
+ * unlikely to be set. It's guaranteed that at least one of the 140
+ * bits is cleared.
+ */
+static inline int _sched_find_first_bit(unsigned long *b)
+{
+	if (unlikely(b[0]))
+		return __ffs(b[0]);
+	if (unlikely(b[1]))
+		return __ffs(b[1]) + 32;
+	if (unlikely(b[2]))
+		return __ffs(b[2]) + 64;
+	if (b[3])
+		return __ffs(b[3]) + 96;
+	return __ffs(b[4]) + 128;
+}
 
 /**
  * ffs - find first bit set
--- linux-2.4.19/include/asm-sparc/system.h.org	Wed Oct 31 00:08:11 2001
+++ linux-2.4.19/include/asm-sparc/system.h	Sat Nov  2 23:54:48 2002
@@ -88,7 +88,7 @@
  *
  * SWITCH_ENTER and SWITH_DO_LAZY_FPU do not work yet (e.g. SMP does not work)
  */
-#define prepare_to_switch() do { \
+#define prepare_arch_switch(rq, next) do { \
 	__asm__ __volatile__( \
 	".globl\tflush_patch_switch\nflush_patch_switch:\n\t" \
 	"save %sp, -0x40, %sp; save %sp, -0x40, %sp; save %sp, -0x40, %sp\n\t" \
@@ -96,6 +96,8 @@
 	"save %sp, -0x40, %sp\n\t" \
 	"restore; restore; restore; restore; restore; restore; restore"); \
 } while(0)
+#define finish_arch_switch(rq, next)	do{ }while(0)
+#define task_running(rq, p)		((rq)->curr == (p))
 
 	/* Much care has gone into this code, do not touch it.
 	 *
--- linux-2.4.19/include/asm-sparc/pgtable.h.org	Mon Sep 23 09:33:03 2002
+++ linux-2.4.19/include/asm-sparc/pgtable.h	Mon Sep 23 10:23:24 2002
@@ -118,6 +118,16 @@
 #define PAGE_COPY      __pgprot(BTFIXUP_INT(page_copy))
 #define PAGE_READONLY  __pgprot(BTFIXUP_INT(page_readonly))
 
+#ifdef CONFIG_GRKERNSEC_PAX
+#define	PAGE_SHARED_NOEXEC	PAGE_SHARED
+#define	PAGE_COPY_NOEXEC	PAGE_COPY
+#define	PAGE_READONLY_NOEXEC	PAGE_READONLY
+#else
+#define	PAGE_SHARED_NOEXEC	PAGE_SHARED
+#define	PAGE_COPY_NOEXEC	PAGE_COPY
+#define	PAGE_READONLY_NOEXEC	PAGE_READONLY
+#endif
+
 extern unsigned long page_kernel;
 
 #ifdef MODULE
--- linux-2.4.19/kernel/sched.c.org	Fri Sep 13 10:27:12 2002
+++ linux-2.4.19/kernel/sched.c	Fri Sep 13 10:12:38 2002
@@ -520,6 +520,11 @@
 {
 	finish_arch_switch(this_rq(), prev);
 }
+#else
+asmlinkage void schedule_tail(task_t *prev)
+{
+	finish_arch_switch(this_rq(), prev);
+}
 #endif
 
 static inline task_t * context_switch(task_t *prev, task_t *next)
